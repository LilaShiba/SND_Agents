{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Neural Diversity \n",
    "## An Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pack import Pack\n",
    "from utils.agent import Agent\n",
    "from utils.metrics import ThoughtDiversity\n",
    "from collections import defaultdict\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_params = [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.9]\n",
    "# agent_hilbert = Agent('agent_hilbert_space',\n",
    "#                       'documents/HilbertSpaceMulti.pdf', 1, embedding_params, False)\n",
    "# agent_hilbert.chat_bot.one_question(\n",
    "#     \"Imagine how hilbert space could be used in a neural network for neuron representation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥  Conjuring up agent_ltoa  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_ltoa is chroma_db/agent_ltoa\n",
      "\n",
      "ğŸ”¥  Conjuring up agent_snd  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_snd is chroma_db/agent_snd\n",
      "\n",
      "ğŸ”¥  Conjuring up agent_foundation  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_foundation is chroma_db/agent_foundation\n",
      "\n",
      "ğŸ”¥  Conjuring up agent_quant  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_quant is chroma_db/agent_quant\n",
      "\n",
      "ğŸ”¥  Conjuring up agent_norbert  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_norbert is chroma_db/agent_norbert\n",
      "\n",
      "ğŸ”¥  Conjuring up agent_cot  ğŸ”¥ \n",
      "\n",
      "ğŸ§™ creating course  ğŸ§™\n",
      "\n",
      "ğŸ”® creating encoder  ğŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ğŸ§š creating chat_bot for  ğŸ§š\n",
      "\n",
      "the path  ğŸŒˆ being used for agent_cot is chroma_db/agent_cot\n",
      "\n",
      "waking up agent agent_ltoa\n",
      "\n",
      "waking up agent agent_snd\n",
      "\n",
      "waking up agent agent_foundation\n",
      "\n",
      "waking up agent agent_quant\n",
      "\n",
      "waking up agent agent_norbert\n",
      "\n",
      "waking up agent agent_cot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_to_act = \"chroma_db/agent_ltoa\"\n",
    "system_neural_diversity = \"chroma_db/agent_snd\"\n",
    "foundational_models = \"chroma_db/agent_foundation\"\n",
    "norbet_cog = \"chroma_db/agent_norbert\"\n",
    "viz_quant = \"chroma_db/agent_quant\"\n",
    "cot_path = \"chroma_db/agent_cot\"\n",
    "\n",
    "embedding_params = [\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.9],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.1],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.5],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.9],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.1],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.5],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.8]\n",
    "]\n",
    "# name, path, cot_type, new_bool\n",
    "agent_specs = [\n",
    "    ['agent_ltoa', learning_to_act, 0, True],\n",
    "    ['agent_snd', system_neural_diversity, 0, True],\n",
    "    ['agent_foundation', foundational_models, 0, True],\n",
    "    ['agent_quant', viz_quant, 0, True],\n",
    "    ['agent_norbert', norbet_cog, 0, True],\n",
    "    ['agent_cot', cot_path, 0, True]\n",
    "]\n",
    "\n",
    "test_pack = Pack(agent_specs, embedding_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15831e08ead4496b443f7e5dad6ce98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = test_pack.update_weighted_edges(\n",
    "    question=\"Imagine how a neuron for a neural network may be reimagined based on the text.\",\n",
    "    weighted_adj_matrix=None, k=3)\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pack.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 1\n",
    "k = 3\n",
    "results = []\n",
    "question = \"Imagine how a neuron for a neural network may be reimagined based on the text.\"\n",
    "\n",
    "for _ in range(rounds):\n",
    "    round_res = test_pack.one_question(question)\n",
    "    # Extract responses from individual agents\n",
    "    responses = [(agent_name, round_res[agent_name])\n",
    "                 for agent_name in test_pack.agent_names if agent_name in round_res]\n",
    "    weights = defaultdict()\n",
    "    if responses:\n",
    "        # Processing each agent's response\n",
    "        for agent_name, response in responses:\n",
    "\n",
    "            prob_vector = test_pack.metrics._prob_vectors(response)\n",
    "            entropy = test_pack.metrics.shannon_entropy(prob_vector)\n",
    "            diversity = test_pack.metrics.true_diversity(prob_vector)\n",
    "            wasserstein = test_pack.metrics.wasserstein(prob_vector)\n",
    "            test_pack.metrics.shannon_entropy_scores.append(entropy)\n",
    "            test_pack.metrics.true_diversity_scores.append(diversity)\n",
    "            agent_name.state = [entropy, diversity, wasserstein]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edges = defaultdict()\n",
    "\n",
    "for idx, node in enumerate(test_pack.agents):\n",
    "    delta_edges = test_pack.knn.search(node.state, k)\n",
    "    test_pack.agents[idx].edges.append([n.name for n in delta_edges])\n",
    "    edges[node.name] = [node.name for node in delta_edges]\n",
    "\n",
    "test_pack.edges = edges\n",
    "test_pack.graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
