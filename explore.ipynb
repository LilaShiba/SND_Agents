{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pack import Pack\n",
    "from utils.agent import Agent\n",
    "from utils.metrics import ThoughtDiversity\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_params = [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.7]\n",
    "agent_hilbert = Agent('agent_hilbert_space',\n",
    "                      'documents/HilbertSpaceMulti.pdf', 1, embedding_params, False)\n",
    "agent_hilbert.chat_bot.one_question(\"What is hilbert space?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥  Conjuring up agent_ltoa  ðŸ”¥ \n",
      "\n",
      "ðŸ§™ creating course  ðŸ§™\n",
      "\n",
      "ðŸ”® creating encoder  ðŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ðŸ§š creating chat_bot for  ðŸ§š\n",
      "\n",
      "the path  ðŸŒˆ being used for agent_ltoa is chroma_db/agent_ltoa\n",
      "\n",
      "ðŸ”¥  Conjuring up agent_snd  ðŸ”¥ \n",
      "\n",
      "ðŸ§™ creating course  ðŸ§™\n",
      "\n",
      "ðŸ”® creating encoder  ðŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ðŸ§š creating chat_bot for  ðŸ§š\n",
      "\n",
      "the path  ðŸŒˆ being used for agent_snd is chroma_db/agent_snd\n",
      "\n",
      "ðŸ”¥  Conjuring up agent_foundation  ðŸ”¥ \n",
      "\n",
      "ðŸ§™ creating course  ðŸ§™\n",
      "\n",
      "ðŸ”® creating encoder  ðŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ðŸ§š creating chat_bot for  ðŸ§š\n",
      "\n",
      "the path  ðŸŒˆ being used for agent_foundation is chroma_db/agent_foundation\n",
      "\n",
      "ðŸ”¥  Conjuring up agent_quant  ðŸ”¥ \n",
      "\n",
      "ðŸ§™ creating course  ðŸ§™\n",
      "\n",
      "ðŸ”® creating encoder  ðŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ðŸ§š creating chat_bot for  ðŸ§š\n",
      "\n",
      "the path  ðŸŒˆ being used for agent_quant is chroma_db/agent_quant\n",
      "\n",
      "ðŸ”¥  Conjuring up agent_norbert  ðŸ”¥ \n",
      "\n",
      "ðŸ§™ creating course  ðŸ§™\n",
      "\n",
      "ðŸ”® creating encoder  ðŸ”® \n",
      "loading agent...\n",
      "agent loaded\n",
      "\n",
      "ðŸ§š creating chat_bot for  ðŸ§š\n",
      "\n",
      "the path  ðŸŒˆ being used for agent_norbert is chroma_db/agent_norbert\n",
      "\n",
      "waking up agent agent_ltoa\n",
      "âš«\n",
      "waking up agent agent_snd\n",
      "âš«\n",
      "waking up agent agent_foundation\n",
      "âš«\n",
      "waking up agent agent_quant\n",
      "âš«\n",
      "waking up agent agent_norbert\n",
      "âš«\n"
     ]
    }
   ],
   "source": [
    "learning_to_act = \"chroma_db/agent_ltoa\"\n",
    "system_neural_diversity = \"chroma_db/agent_snd\"\n",
    "foundational_models = \"chroma_db/agent_foundation\"\n",
    "norbet_cog = 'chroma_db/agent_norbert'\n",
    "viz_quant = \"chroma_db/agent_quant\"\n",
    "\n",
    "embedding_params = [\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.9],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.1],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.5],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.9],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.1],\n",
    "    [\"facebook-dpr-ctx_encoder-multiset-base\", 200, 25, 0.5]\n",
    "]\n",
    "# name, path, cot_type, new_bool\n",
    "agent_specs = [\n",
    "    ['agent_ltoa', learning_to_act, 0, True],\n",
    "    ['agent_snd', system_neural_diversity, 0, True],\n",
    "    ['agent_foundation', foundational_models, 0, True],\n",
    "    ['agent_quant', viz_quant, 0, True],\n",
    "    ['agent_norbert', norbet_cog, 0, True]\n",
    "]\n",
    "\n",
    "test_pack = Pack(agent_specs, embedding_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'agent_ltoa': [<utils.agent.Agent at 0x7fbbc0d47d90>,\n",
       "              <utils.agent.Agent at 0x7fbb59ac18d0>,\n",
       "              <utils.agent.Agent at 0x7fbb848b9450>],\n",
       "             'agent_snd': [<utils.agent.Agent at 0x7fbbc0d47e80>,\n",
       "              <utils.agent.Agent at 0x7fbb593bd630>,\n",
       "              <utils.agent.Agent at 0x7fbb59ac18d0>],\n",
       "             'agent_foundation': [<utils.agent.Agent at 0x7fbb59ac18d0>,\n",
       "              <utils.agent.Agent at 0x7fbbc0d47d90>,\n",
       "              <utils.agent.Agent at 0x7fbbc0d47e80>],\n",
       "             'agent_quant': [<utils.agent.Agent at 0x7fbb848b9450>,\n",
       "              <utils.agent.Agent at 0x7fbbc0d47d90>,\n",
       "              <utils.agent.Agent at 0x7fbb59ac18d0>],\n",
       "             'agent_norbert': [<utils.agent.Agent at 0x7fbb593bd630>,\n",
       "              <utils.agent.Agent at 0x7fbbc0d47e80>,\n",
       "              <utils.agent.Agent at 0x7fbb59ac18d0>]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pack.update_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Graph Theory for Neural Structure :)\n",
    "\n",
    "formatted_edges = []\n",
    "network = nx.Graph(formatted_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ThoughtDiversity(test_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.monte_carlo_sim(\"How can we imbue humaness in AI agents?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
