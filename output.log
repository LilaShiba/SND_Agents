2023-11-23 21:16:44,622 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-23 21:16:44,632 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-23 21:16:44,634 - DEBUG - interactive is False
2023-11-23 21:16:44,634 - DEBUG - platform is darwin
2023-11-23 21:16:44,744 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-23 21:16:44,748 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-23 21:16:50,593 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:16:52,913 - INFO - Use pytorch device: cpu
2023-11-23 21:16:52,914 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:16:54,405 - INFO - Use pytorch device: cpu
2023-11-23 21:16:54,532 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:16:54,661 - DEBUG - Starting component System
2023-11-23 21:16:54,661 - DEBUG - Starting component Posthog
2023-11-23 21:16:54,661 - DEBUG - Starting component SqliteDB
2023-11-23 21:16:54,670 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:16:54,670 - DEBUG - Starting component SegmentAPI
2023-11-23 21:16:54,675 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:16:55,223 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-23 21:16:55,609 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:16:56,065 - INFO - Use pytorch device: cpu
2023-11-23 21:16:56,067 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:16:58,964 - INFO - Use pytorch device: cpu
2023-11-23 21:16:58,965 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:00,708 - INFO - Use pytorch device: cpu
2023-11-23 21:17:00,711 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:00,714 - DEBUG - Starting component System
2023-11-23 21:17:00,714 - DEBUG - Starting component Posthog
2023-11-23 21:17:00,714 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:00,721 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:00,721 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:00,726 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:01,206 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:04,210 - INFO - Use pytorch device: cpu
2023-11-23 21:17:04,212 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:05,844 - INFO - Use pytorch device: cpu
2023-11-23 21:17:05,845 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:07,174 - INFO - Use pytorch device: cpu
2023-11-23 21:17:07,177 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:07,178 - DEBUG - Starting component System
2023-11-23 21:17:07,179 - DEBUG - Starting component Posthog
2023-11-23 21:17:07,179 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:07,182 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:07,182 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:07,184 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:07,420 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:12,439 - INFO - Use pytorch device: cpu
2023-11-23 21:17:12,457 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:15,944 - INFO - Use pytorch device: cpu
2023-11-23 21:17:15,945 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:19,813 - INFO - Use pytorch device: cpu
2023-11-23 21:17:19,842 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:19,868 - DEBUG - Starting component System
2023-11-23 21:17:19,869 - DEBUG - Starting component Posthog
2023-11-23 21:17:19,870 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:19,885 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:19,885 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:19,902 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:20,112 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:23,263 - INFO - Use pytorch device: cpu
2023-11-23 21:17:23,265 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:26,081 - INFO - Use pytorch device: cpu
2023-11-23 21:17:26,082 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:28,692 - INFO - Use pytorch device: cpu
2023-11-23 21:17:28,698 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:28,700 - DEBUG - Starting component System
2023-11-23 21:17:28,700 - DEBUG - Starting component Posthog
2023-11-23 21:17:28,700 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:28,709 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:28,709 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:28,713 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:29,382 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:32,076 - INFO - Use pytorch device: cpu
2023-11-23 21:17:32,078 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:35,073 - INFO - Use pytorch device: cpu
2023-11-23 21:17:35,074 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:38,275 - INFO - Use pytorch device: cpu
2023-11-23 21:17:38,291 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:38,296 - DEBUG - Starting component System
2023-11-23 21:17:38,297 - DEBUG - Starting component Posthog
2023-11-23 21:17:38,297 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:38,311 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:38,311 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:38,321 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:17:38,551 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:44,312 - INFO - Use pytorch device: cpu
2023-11-23 21:17:44,339 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,344 - DEBUG - Starting component System
2023-11-23 21:17:44,345 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,345 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,359 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,360 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,382 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,387 - DEBUG - Starting component System
2023-11-23 21:17:44,387 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,387 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,397 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,397 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,406 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,410 - DEBUG - Starting component System
2023-11-23 21:17:44,411 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,411 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,420 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,421 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,428 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,429 - DEBUG - Starting component System
2023-11-23 21:17:44,429 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,429 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,436 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,436 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,443 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,444 - DEBUG - Starting component System
2023-11-23 21:17:44,445 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,445 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,460 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,460 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,466 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:17:44,469 - DEBUG - Starting component System
2023-11-23 21:17:44,470 - DEBUG - Starting component Posthog
2023-11-23 21:17:44,470 - DEBUG - Starting component SqliteDB
2023-11-23 21:17:44,477 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:17:44,477 - DEBUG - Starting component SegmentAPI
2023-11-23 21:17:44,714 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:17:47,840 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:17:48,014 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:17:48,015 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:17:48,015 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:17:48,059 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:17:51,070 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:17:51,080 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2312 request_id=a198bbe30e365a0a229dd583290f8aaf response_code=200
2023-11-23 21:17:52,874 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:17:53,378 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:17:53,378 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n by these actors \\u2014 like using a more efficient model \\u2014 can scale to massive carbon savings, which would otherwise\\nrequire a massive campaign to reach all downstream model users.\\n\\n by these actors \\u2014 like using a more efficient model \\u2014 can scale to massive carbon savings, which would otherwise\\nrequire a massive campaign to reach all downstream model users."}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:19:39,560 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:19:39,562 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:19:39,627 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-23 21:19:41,968 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:19:41,969 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1777 request_id=8f70f6fb1ee64f78ef78fd81fc9b4e75 response_code=200
2023-11-23 21:19:42,567 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:19:42,567 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n by these actors \\u2014 like using a more efficient model \\u2014 can scale to massive carbon savings, which would otherwise\\nrequire a massive campaign to reach all downstream model users.\\n\\n by these actors \\u2014 like using a more efficient model \\u2014 can scale to massive carbon savings, which would otherwise\\nrequire a massive campaign to reach all downstream model users."}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:19:42,972 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:19:42,973 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=229 request_id=c399287f99fe1763b18597c8314cd2f9 response_code=200
2023-11-23 21:19:44,839 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:19:44,925 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:19:44,926 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks."}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:19:47,142 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:19:47,149 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1930 request_id=f01e72e6eb5dfae438457f4ece7dfcd2 response_code=200
2023-11-23 21:19:48,588 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:19:48,858 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:19:48,858 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15"}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:19:51,085 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:19:51,086 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1923 request_id=c3445d7618827dc7f47299e0c7d4dc24 response_code=200
2023-11-23 21:19:52,024 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:19:52,408 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:19:52,408 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 41 \\ndisplays of the interface, moving to the perceptual processing of those \\ndisplays, to its interpretation, and finally, to the evaluation -the com - \\nparison of the interpretation of system state with the original goals and \\nintention. But in doing all this, there is one more problem, one just \\nbeginning to be understood, and one not assisted by the usual forms of \\ndisplays: the problem of level. There may be many levels of outcomes \\nthat must be matched with different levels of intentions (see Norman, \\n1981a; Rasmussen in press; Rasmussen & Lind, 1981). And, finally, \\nif the change in system state does not occur immediately following the \\nexecution of the action sequence, the resulting delay can severely \\nimpede the process of evaluation, for the user may no longer remember \\nthe details of the intentions or the action sequence. \\nStages of User Activities \\nA convenient summary of the analysis of tasks is is that the process of \\nperforming and evaluating an action can be approximated by seven \\nstages of user activity\\u2019 (Figure 3.3): \\n0 Establishing the Goal \\nForming the Intention \\n0 Specifying the Action Sequence \\n0 Executing the Action \\n0 Perceiving the System State \\n0 Interpreting the State \\n0 Evaluating the System State with respect to the Goals \\nand Intentions \\n3 The last two times I spoke of an approximate theory of action (Norman, 1984a. 1985) \\nI spoke of four stages. Now I speak of seven. An explanation seems to be in order. \\nThe answer really is simple. The full theory of action is not yet in existence, but whatev - \\ner its form, it involves a continuum of stages on both the action/execution side and the \\nperception/evaluation side. The notion of stages is a simplification of the underlying \\ntheory: I do not believe that there really are clean, separable stages. However, for prac- \\ntical application, approximating the activity into stages seems reasonable and useful. Just \\nwhat division of stages should be made, however, seems less clear. In my original for- \\nmulations, I suggested four stages: intention, action sequence, execution, and evaluation. \\nIn this chapter I separated goals and intentions and expanded the analysis of evaluation \\nby adding perception and interpretation, thus making the stages of evaluation correspond \\nbetter with the stages of execution: Perception is the evaluatory equivalent of execution, \\ninterpretation the equivalent of the action sequence, and evaluation the equivalent of \\nforming the intention. The present formulation seems a richer, more satisfactory \\nanalysis. \\n\\n3. COGNITIVE ENGINEERING 41 \\ndisplays of the interface, moving to the perceptual processing of those \\ndisplays, to its interpretation, and finally, to the evaluation -the com - \\nparison of the interpretation of system state with the original goals and \\nintention. But in doing all this, there is one more problem, one just \\nbeginning to be understood, and one not assisted by the usual forms of \\ndisplays: the problem of level. There may be many levels of outcomes \\nthat must be matched with different levels of intentions (see Norman, \\n1981a; Rasmussen in press; Rasmussen & Lind, 1981). And, finally, \\nif the change in system state does not occur immediately following the \\nexecution of the action sequence, the resulting delay can severely \\nimpede the process of evaluation, for the user may no longer remember \\nthe details of the intentions or the action sequence. \\nStages of User Activities \\nA convenient summary of the analysis of tasks is is that the process of \\nperforming and evaluating an action can be approximated by seven \\nstages of user activity\\u2019 (Figure 3.3): \\n0 Establishing the Goal \\nForming the Intention \\n0 Specifying the Action Sequence \\n0 Executing the Action \\n0 Perceiving the System State \\n0 Interpreting the State \\n0 Evaluating the System State with respect to the Goals \\nand Intentions \\n3 The last two times I spoke of an approximate theory of action (Norman, 1984a. 1985) \\nI spoke of four stages. Now I speak of seven. An explanation seems to be in order. \\nThe answer really is simple. The full theory of action is not yet in existence, but whatev - \\ner its form, it involves a continuum of stages on both the action/execution side and the \\nperception/evaluation side. The notion of stages is a simplification of the underlying \\ntheory: I do not believe that there really are clean, separable stages. However, for prac- \\ntical application, approximating the activity into stages seems reasonable and useful. Just \\nwhat division of stages should be made, however, seems less clear. In my original for- \\nmulations, I suggested four stages: intention, action sequence, execution, and evaluation. \\nIn this chapter I separated goals and intentions and expanded the analysis of evaluation \\nby adding perception and interpretation, thus making the stages of evaluation correspond \\nbetter with the stages of execution: Perception is the evaluatory equivalent of execution, \\ninterpretation the equivalent of the action sequence, and evaluation the equivalent of \\nforming the intention. The present formulation seems a richer, more satisfactory \\nanalysis. \\n\\n3. COGNITIVE ENGINEERING 41 \\ndisplays of the interface, moving to the perceptual processing of those \\ndisplays, to its interpretation, and finally, to the evaluation -the com - \\nparison of the interpretation of system state with the original goals and \\nintention. But in doing all this, there is one more problem, one just \\nbeginning to be understood, and one not assisted by the usual forms of \\ndisplays: the problem of level. There may be many levels of outcomes \\nthat must be matched with different levels of intentions (see Norman, \\n1981a; Rasmussen in press; Rasmussen & Lind, 1981). And, finally, \\nif the change in system state does not occur immediately following the \\nexecution of the action sequence, the resulting delay can severely \\nimpede the process of evaluation, for the user may no longer remember \\nthe details of the intentions or the action sequence. \\nStages of User Activities \\nA convenient summary of the analysis of tasks is is that the process of \\nperforming and evaluating an action can be approximated by seven \\nstages of user activity\\u2019 (Figure 3.3): \\n0 Establishing the Goal \\nForming the Intention \\n0 Specifying the Action Sequence \\n0 Executing the Action \\n0 Perceiving the System State \\n0 Interpreting the State \\n0 Evaluating the System State with respect to the Goals \\nand Intentions \\n3 The last two times I spoke of an approximate theory of action (Norman, 1984a. 1985) \\nI spoke of four stages. Now I speak of seven. An explanation seems to be in order. \\nThe answer really is simple. The full theory of action is not yet in existence, but whatev - \\ner its form, it involves a continuum of stages on both the action/execution side and the \\nperception/evaluation side. The notion of stages is a simplification of the underlying \\ntheory: I do not believe that there really are clean, separable stages. However, for prac- \\ntical application, approximating the activity into stages seems reasonable and useful. Just \\nwhat division of stages should be made, however, seems less clear. In my original for- \\nmulations, I suggested four stages: intention, action sequence, execution, and evaluation. \\nIn this chapter I separated goals and intentions and expanded the analysis of evaluation \\nby adding perception and interpretation, thus making the stages of evaluation correspond \\nbetter with the stages of execution: Perception is the evaluatory equivalent of execution, \\ninterpretation the equivalent of the action sequence, and evaluation the equivalent of \\nforming the intention. The present formulation seems a richer, more satisfactory \\nanalysis. \\n\\n3. COGNITIVE ENGINEERING 41 \\ndisplays of the interface, moving to the perceptual processing of those \\ndisplays, to its interpretation, and finally, to the evaluation -the com - \\nparison of the interpretation of system state with the original goals and \\nintention. But in doing all this, there is one more problem, one just \\nbeginning to be understood, and one not assisted by the usual forms of \\ndisplays: the problem of level. There may be many levels of outcomes \\nthat must be matched with different levels of intentions (see Norman, \\n1981a; Rasmussen in press; Rasmussen & Lind, 1981). And, finally, \\nif the change in system state does not occur immediately following the \\nexecution of the action sequence, the resulting delay can severely \\nimpede the process of evaluation, for the user may no longer remember \\nthe details of the intentions or the action sequence. \\nStages of User Activities \\nA convenient summary of the analysis of tasks is is that the process of \\nperforming and evaluating an action can be approximated by seven \\nstages of user activity\\u2019 (Figure 3.3): \\n0 Establishing the Goal \\nForming the Intention \\n0 Specifying the Action Sequence \\n0 Executing the Action \\n0 Perceiving the System State \\n0 Interpreting the State \\n0 Evaluating the System State with respect to the Goals \\nand Intentions \\n3 The last two times I spoke of an approximate theory of action (Norman, 1984a. 1985) \\nI spoke of four stages. Now I speak of seven. An explanation seems to be in order. \\nThe answer really is simple. The full theory of action is not yet in existence, but whatev - \\ner its form, it involves a continuum of stages on both the action/execution side and the \\nperception/evaluation side. The notion of stages is a simplification of the underlying \\ntheory: I do not believe that there really are clean, separable stages. However, for prac- \\ntical application, approximating the activity into stages seems reasonable and useful. Just \\nwhat division of stages should be made, however, seems less clear. In my original for- \\nmulations, I suggested four stages: intention, action sequence, execution, and evaluation. \\nIn this chapter I separated goals and intentions and expanded the analysis of evaluation \\nby adding perception and interpretation, thus making the stages of evaluation correspond \\nbetter with the stages of execution: Perception is the evaluatory equivalent of execution, \\ninterpretation the equivalent of the action sequence, and evaluation the equivalent of \\nforming the intention. The present formulation seems a richer, more satisfactory \\nanalysis. "}, {"role": "user", "content": "Imagine how a neuron for a neural network may be reimagined based on the text."}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:20:50,247 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:20:50,248 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;"}, {"role": "user", "content": "Imagine how can one design a better human?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:20:50,249 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:20:50,254 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:22:47,135 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-23 21:22:47,145 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-23 21:22:47,148 - DEBUG - interactive is False
2023-11-23 21:22:47,148 - DEBUG - platform is darwin
2023-11-23 21:22:47,253 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-23 21:22:47,257 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-23 21:22:53,632 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:22:55,646 - INFO - Use pytorch device: cpu
2023-11-23 21:22:55,647 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:22:56,861 - INFO - Use pytorch device: cpu
2023-11-23 21:22:57,001 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:22:57,118 - DEBUG - Starting component System
2023-11-23 21:22:57,118 - DEBUG - Starting component Posthog
2023-11-23 21:22:57,119 - DEBUG - Starting component SqliteDB
2023-11-23 21:22:57,126 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:22:57,126 - DEBUG - Starting component SegmentAPI
2023-11-23 21:22:57,131 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:22:57,678 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-23 21:22:58,083 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:22:58,514 - INFO - Use pytorch device: cpu
2023-11-23 21:22:58,514 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:22:59,838 - INFO - Use pytorch device: cpu
2023-11-23 21:22:59,838 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:23:02,789 - INFO - Use pytorch device: cpu
2023-11-23 21:23:02,793 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:23:02,796 - DEBUG - Starting component System
2023-11-23 21:23:02,796 - DEBUG - Starting component Posthog
2023-11-23 21:23:02,797 - DEBUG - Starting component SqliteDB
2023-11-23 21:23:02,803 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:23:02,803 - DEBUG - Starting component SegmentAPI
2023-11-23 21:23:02,809 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:23:03,177 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:23:04,995 - INFO - Use pytorch device: cpu
2023-11-23 21:23:04,996 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:23:07,721 - INFO - Use pytorch device: cpu
2023-11-23 21:23:07,721 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:23:09,314 - INFO - Use pytorch device: cpu
2023-11-23 21:23:09,316 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:23:09,318 - DEBUG - Starting component System
2023-11-23 21:23:09,318 - DEBUG - Starting component Posthog
2023-11-23 21:23:09,318 - DEBUG - Starting component SqliteDB
2023-11-23 21:23:09,324 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:23:09,324 - DEBUG - Starting component SegmentAPI
2023-11-23 21:23:09,327 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:23:09,777 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:23:11,678 - INFO - Use pytorch device: cpu
2023-11-23 21:23:11,682 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:23:11,683 - DEBUG - Starting component System
2023-11-23 21:23:11,683 - DEBUG - Starting component Posthog
2023-11-23 21:23:11,683 - DEBUG - Starting component SqliteDB
2023-11-23 21:23:11,689 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:23:11,689 - DEBUG - Starting component SegmentAPI
2023-11-23 21:23:11,693 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:23:11,694 - DEBUG - Starting component System
2023-11-23 21:23:11,694 - DEBUG - Starting component Posthog
2023-11-23 21:23:11,694 - DEBUG - Starting component SqliteDB
2023-11-23 21:23:11,698 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:23:11,699 - DEBUG - Starting component SegmentAPI
2023-11-23 21:23:11,703 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:23:11,705 - DEBUG - Starting component System
2023-11-23 21:23:11,706 - DEBUG - Starting component Posthog
2023-11-23 21:23:11,706 - DEBUG - Starting component SqliteDB
2023-11-23 21:23:11,709 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:23:11,709 - DEBUG - Starting component SegmentAPI
2023-11-23 21:23:11,851 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:23:12,989 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:23:13,115 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:23:13,116 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;"}, {"role": "user", "content": "Imagine how can one design a better human?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:23:13,117 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:23:13,179 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:23:17,514 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:23:17,517 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3767 request_id=4a57f5a52fc200ba03636e0cf7240fef response_code=200
2023-11-23 21:23:18,032 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:23:18,684 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:23:18,684 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n to perform well in diverse contexts.\\n\\n to perform well in diverse contexts.\\n\\n by eliminating the computational burden of\\ntraining from scratch, and reducing the extent that previously-learned concepts must be re-learned\\ndue to forgetting.\\n\\n by eliminating the computational burden of\\ntraining from scratch, and reducing the extent that previously-learned concepts must be re-learned\\ndue to forgetting."}, {"role": "user", "content": "Imagine how can one design a better human?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:23:19,160 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:23:19,162 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=248 request_id=b1b475745f5049ed1a2fc5e21bd44019 response_code=200
2023-11-23 21:23:19,879 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:23:20,112 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:23:20,113 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine how can one design a better human?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:23:20,891 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:23:20,892 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=508 request_id=2f59b9dc3f059be6948de777edf9a60e response_code=200
2023-11-23 21:23:20,894 - INFO - 1.2792334921876884
2023-11-23 21:23:20,898 - INFO - 1.2792334921876884
2023-11-23 21:23:20,899 - INFO - 1.2792334921876884
2023-11-23 21:23:20,933 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-23 21:23:20,934 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-23 21:23:20,956 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,957 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,958 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,959 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-23 21:23:20,960 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,961 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,962 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-23 21:23:20,963 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,964 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,965 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,966 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,967 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,968 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,969 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,970 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,971 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,972 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:23:20,973 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,974 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,975 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,976 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,977 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,977 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,977 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,977 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-23 21:23:20,977 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,978 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,979 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,980 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:23:20,980 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,980 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,980 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,981 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,982 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,983 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,984 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,985 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,986 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,987 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,988 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,989 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:23:20,990 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,991 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:23:20,992 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-23 21:23:20,993 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,994 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,994 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:23:20,994 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-23 21:26:01,098 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:26:01,100 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;"}, {"role": "user", "content": "Imagine how can one design a better human based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:26:04,732 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:26:04,751 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3243 request_id=da66979648adbe41a52f8c8a3861fe47 response_code=200
2023-11-23 21:26:05,888 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:26:05,888 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n to perform well in diverse contexts.\\n\\n to perform well in diverse contexts.\\n\\n by eliminating the computational burden of\\ntraining from scratch, and reducing the extent that previously-learned concepts must be re-learned\\ndue to forgetting.\\n\\n by eliminating the computational burden of\\ntraining from scratch, and reducing the extent that previously-learned concepts must be re-learned\\ndue to forgetting."}, {"role": "user", "content": "Imagine how can one design a better human based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:27:28,028 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:27:28,028 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;"}, {"role": "user", "content": "Imagine how can one design a better human based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:27:28,029 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:27:28,123 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:28:15,087 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:28:15,087 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\nTable 2: Table of Results. Means and standard deviations over\\n100episodes, and number of parameters optimized for each experi-\\nmental setting. Scores are evaluated with the most successful run\\nin each setting. For context, results from Weight Agnostic Neural\\nNetworks (WANN) [ 20] are included as another method that does\\nnot optimize weights. Number of parameters listed for WANN are\\nthe final number of connections in the evolved structure.\\nModel Score # Param.\\nSimple Neurons 892 \\u00b1177 396\\nRec. Neurons 916 \\u00b179 1,259\\nCartPoleSwingUp Small FFNN 805 \\u00b1296 1,281\\nSame FFNN 922\\u00b173 9,089\\nWANN 732 \\u00b116 52\\nSimple Neurons 239 \\u00b152 440\\nRec. Neurons 295 \\u00b163 1,325\\nBipedalWalker Small FFNN 240 \\u00b159 1,396\\nSame FFNN 318\\u00b146 11,716\\nWANN 261 \\u00b158 210\\nSimple Neurons 820 \\u00b1118 1,686\\nRec. Neurons 822\\u00b174 5,218\\nCarRacing Small FFNN 798 \\u00b1172 5,219\\nSame FFNN 752 \\u00b1171 91,523\\nWANN 608\\u00b1161 245\\nreason, we instead use Evolution Strategy (sometimes referred to\\nas \\u201cOpenES\\u201d [ 24]) as described by Salimans et al .[50] and. We use\\na population size of 128and otherwise use the default parameters\\nof the implementation [24].\\n5 RESULTS\\nEvaluations of the most successful runs of each experimental setting\\nare summarized in Table 2. All experimental settings achieved good\\nscores on the CartPoleSwingUp task. Only the weight-optimized\\nnetwork with hidden layers of size 128and64managed to average a\\nscore above 300points over 100episodes in the BipedalWalker-v3\\nenvironment. However, the optimized recurrent neurons in a ran-\\ndom network came close with just a fraction of the number of opti-\\nmized parameters. The smaller weight-optimized network ( Small\\nFFNN ) and the simple neurons achieved similar scores of 240and\\n239, respectively. This is indicative of the agent having learned\\nto walk to the end of the level in most cases but in an inefficient\\nmanner.\\nIn the CarRacing-v3 environment, the agent based on recurrent\\nneurons scored the highest, though none of the approaches reached\\nan average score above 900over 100episode, which is needed for\\nthe task to be considered solved. However, with a mean score above\\n800, the agent was able to successfully complete the majority of\\nthe procedurally generated test episodes. Training curves for all\\nexperimental settings can be found in Figure 4.5.1 Investigating Evolved Neurons\\nTo gain a better idea of how a neural network with random weights\\nbut optimized neuro-centric parameters is solving the task, we\\nplotted all activated neurons of a layer of the champion network\\n(Fig. 3) of the CarRacing environment. The figure shows that while\\nseveral of the found activations look like the standard form we\\nwould expect from a hyperbolic tangent function with a bias, many\\nof the other types of functions also emerged after optimization. We\\nsee functions with strong oscillatory behaviors, some in the whole\\ninput space, and some only in smaller sections. Other functions\\nhave extra peaks and valleys compared to the standard hyperbolic\\ntangent. We hypothesize that this property allows each neuron\\nto respond with more nuance to its input. Additionally, given the\\nsame inputs, this collection of neurons responds diversely. As seen\\nin Table 2, this evolved diversity of neural computations within a\\nlayer allowed the agents to perform well, even though information\\nbetween layers is projected randomly. For a similar depiction of the\\nactivations of the simple, non-recurrent neurons, see Figure 5.\\n5.2 Comparison to Weight Agnostic Neural\\nNetworks\\nAn approach similar in spirit to ours is the weight agnostic neural\\nnetwork (WANN) approach by Gaier and Ha [ 20]. As detailed in\\nSection 2, in WANNs, only the architecture of the neural network\\nis learned (including choosing an activation function from a prede-\\nfined set for each neuron) while avoiding weight training. While an\\napples-to-apples comparison is not possible (due to different opti-\\nmization algorithms), it is nevertheless interesting to see how these\\ntwo methods compare in terms of performance. Since connections\\nare added to the WANN models during optimization, we cannot\\ndirectly compare the number of parameters that were optimized\\nin these models to that of the neural units. In Table 2, we simply\\nlist the final number of synapses in the evolved network structures\\nreported by Gaier and Ha, to give an idea of the network sizes. The\\noptimized neurons tend to score better in all three environments.\\nThese results suggest that it might be easier to optimize customiz-\\nable neural units for each position in a fully connected network\\nthan it is to learn a network structure from scratch.\\nIn the future, these approaches could be complementary. We\\nimagine that extending the WANN approach with more expressive\\nneurons could allow their evolved neural architectures to become\\nsignificantly more compact and higher performing.\\n6 DISCUSSION AND FUTURE WORK\\nIn this paper, we introduced an approach to optimize parameter-\\nized, stateful neurons. Training these alone yielded neural networks\\nthat can control agents in the CartPoleSwingUp ,CarRacing , and\\nBipedalWalker environments, even when the weights of the net-\\nwork were never optimized. While optimizing small neural units\\nalone is unlikely to beat state-of-the-art methods on complicated\\ntasks, the neuro-centric optimization alone did nevertheless enable\\nmeaningful behavioral changes in the agents. We find these results\\nencouraging, as they pave the way for interesting future studies.\\nThe largest weight-optimized network (Same FFNN) achieved\\nsuperior scores compared to the neural units in the CartPole-\\nSwingUp andBipedalWalker environments. This is not surprising;"}, {"role": "user", "content": "Imagine how can one design a better human based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:28:15,091 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-23 21:28:59,895 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:28:59,895 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine how can one design a better neuron based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:28:59,998 - DEBUG - Starting new HTTPS connection (3): api.openai.com:443
2023-11-23 21:29:03,882 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:29:03,885 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3368 request_id=c238919028b03bc78921a6f30b19d347 response_code=200
2023-11-23 21:29:04,037 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:29:04,038 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBER"}, {"role": "user", "content": "Imagine how can one design a better neuron based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:29:05,504 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:29:05,506 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1311 request_id=c5c7e02d589d28d867cceeec895a6f76 response_code=200
2023-11-23 21:29:06,252 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:29:06,252 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks.\\n\\nOn the Opportunities and Risks of Foundation Models 5\\nThere had been considerable progress in self-supervised learning dating back to word embeddings\\n[Turian et al .2010; Mikolov et al .2013; Pennington et al .2014], which associated each word with a\\ncontext-independent vector, provided the basis for a wide range of NLP models. Shortly thereafter,\\nself-supervised learning based on autoregressive language modeling (predict the next word given\\nthe previous words) [Dai and Le 2015] became popular. This produced models that represented\\nwords in context, such as GPT [Radford et al .2018], ELMo [Peters et al .2018], and ULMFiT [Howard\\nand Ruder 2018].4\\nThe next wave of developments in self-supervised learning \\u2014 BERT [Devlin et al .2019] GPT-2\\n[Radford et al .2019], RoBERTa [Liu et al .2019], T5 [Raffel et al .2019], BART [Lewis et al .2020a] \\u2014\\nquickly followed, embracing the Transformer architecture, incorporating more powerful deep\\nbidirectional encoders of sentences, and scaling up to larger models and datasets.\\nWhile one can view this last wave of technical developments purely through the lens of self-\\nsupervised learning, there was a sociological inflection point around the introduction of BERT.\\nBefore 2019, self-supervised learning with language models was essentially a subarea in NLP, which\\nprogressed in parallel to other developments in NLP. After 2019, self-supervised learning with\\nlanguage models became more of a substrate of NLP, as using BERT has become the norm. The\\nacceptance that a single model could be useful for such a wide range of tasks marks the beginning\\nof the era of foundation models.\\nFoundation models have led to an unprecedented level of homogenization : Almost all state-of-\\nthe-art NLP models are now adapted from one of a few foundation models, such as BERT, RoBERTa,\\nBART, T5, etc. While this homogenization produces extremely high leverage (any improvements in\\nthe foundation models can lead to immediate benefits across all of NLP), it is also a liability; all AI\\nsystems might inherit the same problematic biases of a few foundation models [Bolukbasi et al .\\n2016; Caliskan et al .2017; Abid et al .2021, inter alia ]) \\u2014 see \\u00a75.1: fairness , \\u00a75.6: ethics for further\\ndiscussion.\\nWe are also beginning to see a homogenization across research communities. For example, similar\\nTransformer-based sequence modeling approaches are now applied to text [Devlin et al .2019;\\nRadford et al .2019; Raffel et al .2019], images [Dosovitskiy et al .2020; Chen et al .2020d], speech [Liu\\net al.2020d], tabular data [Yin et al .2020], protein sequences [Rives et al .2021], organic molecules\\n[Rothchild et al .2021], and reinforcement learning [Chen et al .2021b; Janner et al .2021]. These\\nexamples point to a possible future where we have a unified set of tools for developing foundation\\nmodels across a wide range of modalities [Tamkin et al. 2021b].\\nBesides the homogenization of approaches, we also see the homogenization of actual models\\nacross research communities in the form of multimodal models \\u2014 e.g., foundation models trained\\non language and vision data [Luo et al .2020; Kim et al .2021a; Cho et al .2021; Ramesh et al .2021;\\nRadford et al .2021]. Data is naturally multimodal in some domains\\u2014e.g., medical images, structured\\ndata, clinical text in healthcare (\\u00a73.1: healthcare ). Thus, multimodal foundation models are a\\nnatural way of fusing all the relevant information about a domain, and adapting to tasks that also\\nspan multiple modes (Figure 2).\\nFoundation models have also led to surprising emergence which results from scale. For example,\\nGPT-3 [Brown et al .2020], with 175 billion parameters compared to GPT-2\\u2019s 1.5 billion, permits\\nin-context learning , in which the language model can be adapted to a downstream task simply by\\nproviding it with a prompt (a natural language description of the task), an emergent property that\\nwas neither specifically trained for nor anticipated to arise.\\n4The prescient work of Collobert and Weston [2008] is related: they trained on a scalable task akin to masked language\\nmodeling jointly with downstream tasks, rather than producing a single foundation model that can be adapted after the fact\\nto downstream tasks."}, {"role": "user", "content": "Imagine how can one design a better neuron based on the text?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:29:06,733 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:29:06,734 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=311 request_id=212302a962be5cecb54602dd3f114995 response_code=200
2023-11-23 21:29:06,737 - INFO - 1.2792334921876884
2023-11-23 21:29:06,738 - INFO - 1.2792334921876884
2023-11-23 21:29:06,738 - INFO - 1.2792334921876884
2023-11-23 21:30:42,051 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:30:42,051 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:30:42,052 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:30:42,101 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:32:02,050 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:32:02,051 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:32:02,110 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-23 21:32:08,398 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:32:08,400 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4739 request_id=c3c05b4ae162b3f42d23f8d4ca59a3cd response_code=200
2023-11-23 21:32:08,580 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:32:08,580 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.1}' message='Post details'
2023-11-23 21:32:10,138 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:32:10,139 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1317 request_id=8dd5b65cc292a2f85bb0064b4df51556 response_code=200
2023-11-23 21:32:10,368 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:32:10,368 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:32:13,000 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:32:13,001 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2402 request_id=64b20c1a083a56598963ffa03f8d17d4 response_code=200
2023-11-23 21:32:13,004 - INFO - 1.2792334921876884
2023-11-23 21:32:13,005 - INFO - 1.2792334921876884
2023-11-23 21:32:13,006 - INFO - 1.2792334921876884
2023-11-23 21:35:00,733 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-23 21:35:00,749 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-23 21:35:00,751 - DEBUG - interactive is False
2023-11-23 21:35:00,752 - DEBUG - platform is darwin
2023-11-23 21:35:00,856 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-23 21:35:00,860 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-23 21:35:06,929 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:09,498 - INFO - Use pytorch device: cpu
2023-11-23 21:35:09,498 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:10,795 - INFO - Use pytorch device: cpu
2023-11-23 21:35:10,934 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:11,081 - DEBUG - Starting component System
2023-11-23 21:35:11,082 - DEBUG - Starting component Posthog
2023-11-23 21:35:11,082 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:11,092 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:11,092 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:11,097 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:11,645 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-23 21:35:11,831 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:12,442 - INFO - Use pytorch device: cpu
2023-11-23 21:35:12,442 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:13,865 - INFO - Use pytorch device: cpu
2023-11-23 21:35:13,865 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:15,970 - INFO - Use pytorch device: cpu
2023-11-23 21:35:15,974 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:15,975 - DEBUG - Starting component System
2023-11-23 21:35:15,975 - DEBUG - Starting component Posthog
2023-11-23 21:35:15,975 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:15,980 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:15,980 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:15,983 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:16,431 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:18,402 - INFO - Use pytorch device: cpu
2023-11-23 21:35:18,402 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:19,958 - INFO - Use pytorch device: cpu
2023-11-23 21:35:19,958 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:21,693 - INFO - Use pytorch device: cpu
2023-11-23 21:35:21,695 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:21,697 - DEBUG - Starting component System
2023-11-23 21:35:21,697 - DEBUG - Starting component Posthog
2023-11-23 21:35:21,697 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:21,701 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:21,701 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:21,703 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:21,959 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:24,388 - INFO - Use pytorch device: cpu
2023-11-23 21:35:24,389 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:28,009 - INFO - Use pytorch device: cpu
2023-11-23 21:35:28,012 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:32,743 - INFO - Use pytorch device: cpu
2023-11-23 21:35:32,810 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:32,841 - DEBUG - Starting component System
2023-11-23 21:35:32,843 - DEBUG - Starting component Posthog
2023-11-23 21:35:32,843 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:32,864 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:32,864 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:32,885 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:33,163 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:38,453 - INFO - Use pytorch device: cpu
2023-11-23 21:35:38,466 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:42,378 - INFO - Use pytorch device: cpu
2023-11-23 21:35:42,379 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:45,725 - INFO - Use pytorch device: cpu
2023-11-23 21:35:45,739 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:45,748 - DEBUG - Starting component System
2023-11-23 21:35:45,748 - DEBUG - Starting component Posthog
2023-11-23 21:35:45,749 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:45,765 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:45,766 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:45,777 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:46,723 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:51,445 - INFO - Use pytorch device: cpu
2023-11-23 21:35:51,462 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:55,487 - INFO - Use pytorch device: cpu
2023-11-23 21:35:55,489 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:58,162 - INFO - Use pytorch device: cpu
2023-11-23 21:35:58,165 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:58,166 - DEBUG - Starting component System
2023-11-23 21:35:58,167 - DEBUG - Starting component Posthog
2023-11-23 21:35:58,167 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:58,176 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:58,176 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:58,180 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-23 21:35:58,364 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:35:59,766 - INFO - Use pytorch device: cpu
2023-11-23 21:35:59,783 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,785 - DEBUG - Starting component System
2023-11-23 21:35:59,785 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,785 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,794 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,794 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:59,813 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,814 - DEBUG - Starting component System
2023-11-23 21:35:59,814 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,814 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,823 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,823 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:59,828 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,830 - DEBUG - Starting component System
2023-11-23 21:35:59,831 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,831 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,835 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,836 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:59,841 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,841 - DEBUG - Starting component System
2023-11-23 21:35:59,842 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,842 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,847 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,847 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:59,852 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,853 - DEBUG - Starting component System
2023-11-23 21:35:59,853 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,853 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,857 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,857 - DEBUG - Starting component SegmentAPI
2023-11-23 21:35:59,862 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-23 21:35:59,864 - DEBUG - Starting component System
2023-11-23 21:35:59,864 - DEBUG - Starting component Posthog
2023-11-23 21:35:59,864 - DEBUG - Starting component SqliteDB
2023-11-23 21:35:59,866 - DEBUG - Starting component LocalSegmentManager
2023-11-23 21:35:59,866 - DEBUG - Starting component SegmentAPI
2023-11-23 21:36:00,009 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-23 21:36:01,716 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:01,830 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:01,831 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:36:01,833 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-23 21:36:01,898 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-23 21:36:04,115 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:04,125 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1701 request_id=2dc96c1a5d56af66b033ca749a2e7be0 response_code=200
2023-11-23 21:36:06,696 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:07,391 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:07,391 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:36:08,925 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:08,926 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1336 request_id=9589191f1aae471e6b7708e90f79391f response_code=200
2023-11-23 21:36:10,092 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:10,151 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:10,152 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:36:15,887 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:15,889 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5468 request_id=988c8d002028b59b85d701844f169c59 response_code=200
2023-11-23 21:36:18,096 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:18,454 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:18,456 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:36:23,976 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:23,978 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5194 request_id=ed4e638d3bebcfae92edbb4db705ff5c response_code=200
2023-11-23 21:36:24,728 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:25,342 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:25,343 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-23 21:36:26,845 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:26,847 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1202 request_id=0a0ff9766ec086d5873aaa4c847fac55 response_code=200
2023-11-23 21:36:27,497 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-23 21:36:27,789 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-23 21:36:27,790 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-23 21:36:29,829 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-23 21:36:29,830 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1892 request_id=d2170e6725c18e6015c65fe108fc39b5 response_code=200
2023-11-23 21:36:29,864 - INFO - 0.9545461029055546
2023-11-23 21:36:29,869 - INFO - 0.9545461029055546
2023-11-23 21:36:29,869 - INFO - 0.9545461029055546
2023-11-23 21:36:29,870 - INFO - 0.9545461029055546
2023-11-23 21:36:29,870 - INFO - 0.9545461029055546
2023-11-23 21:36:29,870 - INFO - 0.9545461029055546
2023-11-23 21:36:30,024 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-23 21:36:30,042 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-23 21:36:30,190 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-23 21:36:30,196 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,197 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-23 21:36:30,197 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,197 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,198 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-23 21:36:30,199 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,200 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,201 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,201 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,201 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-23 21:36:30,201 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-23 21:36:30,201 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,202 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,202 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,202 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,202 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,202 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,203 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,204 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,205 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,206 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,207 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,208 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,209 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,210 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,211 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,212 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,213 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,213 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,213 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,213 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,214 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,214 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,214 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,215 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,215 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,215 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,215 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,215 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:36:30,216 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,217 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,217 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:36:30,217 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,217 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,218 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,219 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,220 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,221 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,221 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,222 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,223 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,223 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,223 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-23 21:36:30,223 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,224 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,224 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,224 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,224 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-23 21:36:30,224 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:36:30,225 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,226 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,227 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,228 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,229 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,230 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,231 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,232 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,233 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:36:30,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-23 21:36:30,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-23 21:36:30,240 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 09:46:39,278 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 09:46:39,286 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 09:46:39,287 - DEBUG - interactive is False
2023-11-24 09:46:39,287 - DEBUG - platform is darwin
2023-11-24 09:46:39,356 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 09:46:39,359 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 09:46:47,025 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:49,693 - INFO - Use pytorch device: cpu
2023-11-24 09:46:49,696 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:50,870 - INFO - Use pytorch device: cpu
2023-11-24 09:46:51,073 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:46:51,212 - DEBUG - Starting component System
2023-11-24 09:46:51,212 - DEBUG - Starting component Posthog
2023-11-24 09:46:51,212 - DEBUG - Starting component SqliteDB
2023-11-24 09:46:51,221 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:46:51,221 - DEBUG - Starting component SegmentAPI
2023-11-24 09:46:51,228 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:51,805 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 09:46:51,977 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:46:53,278 - INFO - Use pytorch device: cpu
2023-11-24 09:46:53,280 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:54,652 - INFO - Use pytorch device: cpu
2023-11-24 09:46:54,653 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:55,974 - INFO - Use pytorch device: cpu
2023-11-24 09:46:55,996 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:46:55,999 - DEBUG - Starting component System
2023-11-24 09:46:55,999 - DEBUG - Starting component Posthog
2023-11-24 09:46:55,999 - DEBUG - Starting component SqliteDB
2023-11-24 09:46:56,005 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:46:56,005 - DEBUG - Starting component SegmentAPI
2023-11-24 09:46:56,008 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:46:56,059 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:46:58,739 - INFO - Use pytorch device: cpu
2023-11-24 09:46:58,740 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:00,892 - INFO - Use pytorch device: cpu
2023-11-24 09:47:00,894 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:03,476 - INFO - Use pytorch device: cpu
2023-11-24 09:47:03,482 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:03,486 - DEBUG - Starting component System
2023-11-24 09:47:03,486 - DEBUG - Starting component Posthog
2023-11-24 09:47:03,486 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:03,492 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:03,493 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:03,498 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:03,648 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:47:06,742 - INFO - Use pytorch device: cpu
2023-11-24 09:47:06,746 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:08,930 - INFO - Use pytorch device: cpu
2023-11-24 09:47:08,930 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:10,094 - INFO - Use pytorch device: cpu
2023-11-24 09:47:10,097 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:10,098 - DEBUG - Starting component System
2023-11-24 09:47:10,098 - DEBUG - Starting component Posthog
2023-11-24 09:47:10,098 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:10,104 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:10,104 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:10,107 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:10,298 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:47:12,909 - INFO - Use pytorch device: cpu
2023-11-24 09:47:12,913 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:15,134 - INFO - Use pytorch device: cpu
2023-11-24 09:47:15,138 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:17,141 - INFO - Use pytorch device: cpu
2023-11-24 09:47:17,150 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:17,155 - DEBUG - Starting component System
2023-11-24 09:47:17,155 - DEBUG - Starting component Posthog
2023-11-24 09:47:17,155 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:17,160 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:17,160 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:17,166 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:17,404 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:47:19,758 - INFO - Use pytorch device: cpu
2023-11-24 09:47:19,764 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:22,465 - INFO - Use pytorch device: cpu
2023-11-24 09:47:22,466 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:24,497 - INFO - Use pytorch device: cpu
2023-11-24 09:47:24,504 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:24,508 - DEBUG - Starting component System
2023-11-24 09:47:24,508 - DEBUG - Starting component Posthog
2023-11-24 09:47:24,508 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:24,515 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:24,515 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:24,521 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:47:25,060 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:47:26,746 - INFO - Use pytorch device: cpu
2023-11-24 09:47:26,763 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,764 - DEBUG - Starting component System
2023-11-24 09:47:26,764 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,764 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,770 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,770 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:26,789 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,789 - DEBUG - Starting component System
2023-11-24 09:47:26,789 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,790 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,794 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,794 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:26,797 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,797 - DEBUG - Starting component System
2023-11-24 09:47:26,798 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,798 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,801 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,801 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:26,804 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,805 - DEBUG - Starting component System
2023-11-24 09:47:26,805 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,805 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,808 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,808 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:26,813 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,813 - DEBUG - Starting component System
2023-11-24 09:47:26,813 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,814 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,816 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,816 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:26,819 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:47:26,820 - DEBUG - Starting component System
2023-11-24 09:47:26,820 - DEBUG - Starting component Posthog
2023-11-24 09:47:26,820 - DEBUG - Starting component SqliteDB
2023-11-24 09:47:26,822 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:47:26,822 - DEBUG - Starting component SegmentAPI
2023-11-24 09:47:27,156 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:47:28,693 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:47:28,770 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:47:28,770 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:47:28,772 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 09:47:28,821 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 09:47:30,955 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:47:30,961 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1624 request_id=de1bfa67b9f0e92a1542a4089aec06e5 response_code=200
2023-11-24 09:47:32,556 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:47:33,265 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:47:33,266 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:47:37,406 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:47:37,408 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3970 request_id=424bf139d5d4c5a7e6fc9b5afcac807f response_code=200
2023-11-24 09:47:38,812 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:47:38,852 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:47:38,852 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:47:44,981 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:47:44,982 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5868 request_id=5226d4f6b28801561b79b406932175b8 response_code=200
2023-11-24 09:47:45,860 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:47:45,986 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:47:45,987 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15\\n\\nthese issues. To further expand the applicability of quantum algorithms, techniques from novelty search [62]\\nand large language models [63] can be incorporated into these automation engines. Open-ended search in the\\nspace of quantum processes can greatly bene\\ufb01t from a characterization of this landscape, as presented in this\\nwork.\\n5.3 Quantum arti\\ufb01cial general intelligence\\nAmong the more rigorous methods of developing general intelligence is an active formulation of Solomono\\ufb00\\u2019s\\ntheory of inductive intelligence [34], called universal arti\\ufb01cial intelligence [18]. Universal reinforcement learning\\nmodels like AIXI and KSA are capable of rational decision-making or modelling environmental dynamics, based\\non the shortest program that corresponds to compressing the past observations and maximizing a set reward\\nfunction. These have been quantized both by using quantum algorithms, (e.g., in the AIXI-q model [64]) and\\nby applying them to quantum environments (e.g., in the QKSA model [65]).\\nAnother crucial aspect of intelligence [66] is the understanding of cause-e\\ufb00ect relations. Quantum acceler-\\nation of causal inference [67, 68, 69] can bene\\ufb01t from the knowledge of the probability distribution of causal\\noracles, a subset of quantum processes that embed speci\\ufb01c properties of the problem. Besides causal inference,\\nsimilar techniques can be applied to other statistical relational learning applications like probabilistic logic\\nnetworks [70] and quantum variational algorithms.\\nBoth universal distribution and causal inference are intimately connected to the landscape of quantum\\nprograms. This landscape inturn depends on the choice of a speci\\ufb01c gate set, as we saw in this research.\\nThereby, novelty seeking in the space of universal gate sets can meta-optimize quantum program synthesis\\nfor speci\\ufb01c application algorithms. In our current research, we are exploring this direction of second-order\\ncybernetics of automated quantum operational theory, by using the groundwork developed in this article.\\nAcknowledgements\\nThis project was initiated under the QIntern 2021 project \\u201cReinforcement Learning Agent for Quantum\\nFoundations\\u201d. B.G.B., T.A., A.S. would like to thank the organizers of the program and QWorld Associa-\\ntion. A.K. was partially supported by the Polish National Science Center (NCN) under the grant agreement\\n2019/33/B/ST6/02011 . A.S. acknowledges funding from the Dutch Research Council (NWO) through the\\nproject \\u201cQuTech Part III Application-based research\\u201d (project no. 601.QT.001 Part III-C - NISQ ).\\nAuthor contributions\\nConceptualization, A.S.; methodology, A.S., A.K. and B.G.B.; software, B.G.B. and A.K.; writing\\u2013original\\ndraft preparation, A.S., A.K. and B.G.B.; visualization, A.K. and T.A.; supervision, A.S.\\nAll authors have read and agreed to the published version of the manuscript.\\nReferences\\n[1] Koen Bertels, Aritra Sarkar, and Imran Ashraf. Quantum computing\\u2014from nisq to pisq. IEEE Micro , 41(5):24\\u201332, 2021.\\n[2] Koen Bertels, Aritra Sarkar, Thomas Hubregtsen, M Serrao, Abid A Mouedenne, Amitabh Yadav, A Krol, and Imran Ashraf.\\nQuantum computer architecture: Towards full-stack quantum accelerators. In 2020 Design, Automation & Test in Europe\\nConference & Exhibition (DATE) , pages 1\\u20136. IEEE, 2020.\\n[3] John Preskill. Quantum computing in the nisq era and beyond. Quantum , 2:79, 2018.\\n[4] Frank Leymann and Johanna Barzen. The bitter truth about gate-based quantum algorithms in the nisq era. Quantum\\nScience and Technology , 5(4):044007, 2020.\\n[5] Yunong Shi, Pranav Gokhale, Prakash Murali, Jonathan M Baker, Casey Duckering, Yongshan Ding, Natalie C Brown,\\nChristopher Chamberland, Ali Javadi-Abhari, Andrew W Cross, et al. Resource-e\\ufb03cient quantum computing by breaking\\nabstractions. Proceedings of the IEEE , 108(8):1353\\u20131370, 2020.\\n[6] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of research and development ,\\n5(3):183\\u2013191, 1961.\\n[7] Charles H Bennett. Logical reversibility of computation. IBM journal of Research and Development , 17(6):525\\u2013532, 1973.\\n[8] Edward Fredkin and Tommaso To\\ufb00oli. Conservative logic. International Journal of theoretical physics , 21(3-4):219\\u2013253, 1982.\\n[9] Seth Lloyd. Ultimate physical limits to computation. Nature , 406(6799):1047\\u20131054, 2000.\\n[10] Igor L Markov. Limits on fundamental limits to computation. Nature , 512(7513):147\\u2013154, 2014.\\n[11] Stephen Wolfram et al. A new kind of science , volume 5. Wolfram media Champaign, 2002.\\n[12] David Deutsch. Constructor theory. Synthese , 190(18):4331\\u20134359, 2013.\\n[13] Lucien Hardy. Quantum theory from \\ufb01ve reasonable axioms. arXiv preprint quant-ph/0101012 , 2001.\\n[14] Markus P M\\u00a8 uller. Law without law: from observer states to physics via algorithmic information theory. Quantum , 4:301,\\n2020.\\n[15] Tommaso To\\ufb00oli. Action, or the fungibility of computation. In Feynman and computation , pages 349\\u2013392. CRC Press, 2018.\\n15"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:47:57,048 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:47:57,050 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=7213 request_id=6fc1612572b33676dc1d9081a4378016 response_code=200
2023-11-24 09:47:58,767 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:47:59,072 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:47:59,073 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:48:00,769 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:48:00,771 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1504 request_id=8d6784cf09c93046db95013d22c384b0 response_code=200
2023-11-24 09:48:02,796 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:48:02,866 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:48:02,866 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:48:04,766 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:48:04,767 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1710 request_id=b99f1c0a9c86d982c51ec224db0f0a22 response_code=200
2023-11-24 09:48:04,816 - INFO - 0.846282315600138
2023-11-24 09:48:04,827 - INFO - 0.846282315600138
2023-11-24 09:48:04,828 - INFO - 0.846282315600138
2023-11-24 09:48:04,829 - INFO - 0.846282315600138
2023-11-24 09:48:04,829 - INFO - 0.846282315600138
2023-11-24 09:48:04,829 - INFO - 0.846282315600138
2023-11-24 09:48:05,039 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 09:48:05,050 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 09:48:05,219 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 09:48:05,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,230 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 09:48:05,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 09:48:05,234 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 09:48:05,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:48:05,246 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:48:05,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:48:05,265 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 09:49:09,320 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 09:49:09,344 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 09:49:09,356 - DEBUG - interactive is False
2023-11-24 09:49:09,356 - DEBUG - platform is darwin
2023-11-24 09:49:09,732 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 09:49:09,740 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 09:49:22,602 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:27,150 - INFO - Use pytorch device: cpu
2023-11-24 09:49:27,151 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:29,290 - INFO - Use pytorch device: cpu
2023-11-24 09:49:29,500 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:49:29,673 - DEBUG - Starting component System
2023-11-24 09:49:29,673 - DEBUG - Starting component Posthog
2023-11-24 09:49:29,674 - DEBUG - Starting component SqliteDB
2023-11-24 09:49:29,685 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:49:29,685 - DEBUG - Starting component SegmentAPI
2023-11-24 09:49:29,690 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:30,239 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 09:49:30,419 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:49:31,874 - INFO - Use pytorch device: cpu
2023-11-24 09:49:31,875 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:33,619 - INFO - Use pytorch device: cpu
2023-11-24 09:49:33,620 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:36,448 - INFO - Use pytorch device: cpu
2023-11-24 09:49:36,459 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:49:36,462 - DEBUG - Starting component System
2023-11-24 09:49:36,463 - DEBUG - Starting component Posthog
2023-11-24 09:49:36,463 - DEBUG - Starting component SqliteDB
2023-11-24 09:49:36,471 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:49:36,472 - DEBUG - Starting component SegmentAPI
2023-11-24 09:49:36,479 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:37,011 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:49:38,852 - INFO - Use pytorch device: cpu
2023-11-24 09:49:38,853 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:42,105 - INFO - Use pytorch device: cpu
2023-11-24 09:49:42,105 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:44,385 - INFO - Use pytorch device: cpu
2023-11-24 09:49:44,391 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:49:44,393 - DEBUG - Starting component System
2023-11-24 09:49:44,394 - DEBUG - Starting component Posthog
2023-11-24 09:49:44,394 - DEBUG - Starting component SqliteDB
2023-11-24 09:49:44,408 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:49:44,408 - DEBUG - Starting component SegmentAPI
2023-11-24 09:49:44,412 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:44,515 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:49:48,117 - INFO - Use pytorch device: cpu
2023-11-24 09:49:48,120 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:50,761 - INFO - Use pytorch device: cpu
2023-11-24 09:49:50,762 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:53,901 - INFO - Use pytorch device: cpu
2023-11-24 09:49:53,908 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:49:53,912 - DEBUG - Starting component System
2023-11-24 09:49:53,912 - DEBUG - Starting component Posthog
2023-11-24 09:49:53,912 - DEBUG - Starting component SqliteDB
2023-11-24 09:49:53,922 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:49:53,923 - DEBUG - Starting component SegmentAPI
2023-11-24 09:49:53,930 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:49:54,125 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:49:58,056 - INFO - Use pytorch device: cpu
2023-11-24 09:49:58,063 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:01,877 - INFO - Use pytorch device: cpu
2023-11-24 09:50:01,878 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:04,686 - INFO - Use pytorch device: cpu
2023-11-24 09:50:04,699 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:04,703 - DEBUG - Starting component System
2023-11-24 09:50:04,704 - DEBUG - Starting component Posthog
2023-11-24 09:50:04,704 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:04,715 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:04,715 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:04,722 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:05,261 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:50:06,454 - INFO - Use pytorch device: cpu
2023-11-24 09:50:06,456 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:09,707 - INFO - Use pytorch device: cpu
2023-11-24 09:50:09,709 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:13,064 - INFO - Use pytorch device: cpu
2023-11-24 09:50:13,073 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:13,076 - DEBUG - Starting component System
2023-11-24 09:50:13,076 - DEBUG - Starting component Posthog
2023-11-24 09:50:13,076 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:13,083 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:13,083 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:13,088 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:50:13,386 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:50:16,633 - INFO - Use pytorch device: cpu
2023-11-24 09:50:16,657 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,658 - DEBUG - Starting component System
2023-11-24 09:50:16,659 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,659 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,664 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,664 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,681 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,682 - DEBUG - Starting component System
2023-11-24 09:50:16,682 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,682 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,689 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,689 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,695 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,698 - DEBUG - Starting component System
2023-11-24 09:50:16,698 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,699 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,706 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,707 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,711 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,712 - DEBUG - Starting component System
2023-11-24 09:50:16,712 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,712 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,718 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,718 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,722 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,723 - DEBUG - Starting component System
2023-11-24 09:50:16,723 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,723 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,727 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,727 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,731 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:50:16,732 - DEBUG - Starting component System
2023-11-24 09:50:16,732 - DEBUG - Starting component Posthog
2023-11-24 09:50:16,732 - DEBUG - Starting component SqliteDB
2023-11-24 09:50:16,736 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:50:16,736 - DEBUG - Starting component SegmentAPI
2023-11-24 09:50:16,967 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:50:25,477 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:50:25,640 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:50:25,640 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:50:25,641 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 09:50:25,671 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 09:52:05,687 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:52:05,689 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:52:05,753 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-24 09:52:07,779 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:52:07,787 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1753 request_id=dd313a112ad3e766bf8ab1a7e45290f5 response_code=200
2023-11-24 09:52:08,881 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:52:09,303 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:52:09,303 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:52:16,273 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:52:16,275 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6796 request_id=d8cf247aafde2b9ad092981f0676e015 response_code=200
2023-11-24 09:52:17,933 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:52:17,968 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:52:17,968 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:53:45,567 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:53:45,567 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:53:45,568 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 09:53:45,615 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 09:53:52,049 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:53:52,058 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6064 request_id=01189812a982570e961dcb3bb873a4e8 response_code=200
2023-11-24 09:53:52,512 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:53:52,513 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:53:56,006 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:53:56,008 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2611 request_id=104be819f700317677d6110fdd7b36ed response_code=200
2023-11-24 09:53:56,123 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:53:56,123 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:55:19,415 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 09:55:19,426 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 09:55:19,443 - DEBUG - interactive is False
2023-11-24 09:55:19,443 - DEBUG - platform is darwin
2023-11-24 09:55:19,546 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 09:55:19,550 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 09:55:27,989 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:29,804 - INFO - Use pytorch device: cpu
2023-11-24 09:55:29,804 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:30,784 - INFO - Use pytorch device: cpu
2023-11-24 09:55:30,939 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:31,098 - DEBUG - Starting component System
2023-11-24 09:55:31,098 - DEBUG - Starting component Posthog
2023-11-24 09:55:31,098 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:31,106 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:31,107 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:31,112 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:31,645 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 09:55:31,799 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:32,095 - INFO - Use pytorch device: cpu
2023-11-24 09:55:32,095 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:33,136 - INFO - Use pytorch device: cpu
2023-11-24 09:55:33,137 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:34,116 - INFO - Use pytorch device: cpu
2023-11-24 09:55:34,118 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:34,118 - DEBUG - Starting component System
2023-11-24 09:55:34,118 - DEBUG - Starting component Posthog
2023-11-24 09:55:34,118 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:34,122 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:34,122 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:34,124 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:34,355 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:35,342 - INFO - Use pytorch device: cpu
2023-11-24 09:55:35,361 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:38,228 - INFO - Use pytorch device: cpu
2023-11-24 09:55:38,232 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:39,444 - INFO - Use pytorch device: cpu
2023-11-24 09:55:39,451 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:39,454 - DEBUG - Starting component System
2023-11-24 09:55:39,454 - DEBUG - Starting component Posthog
2023-11-24 09:55:39,454 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:39,460 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:39,460 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:39,466 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:39,961 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:41,681 - INFO - Use pytorch device: cpu
2023-11-24 09:55:41,683 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:43,575 - INFO - Use pytorch device: cpu
2023-11-24 09:55:43,575 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:44,670 - INFO - Use pytorch device: cpu
2023-11-24 09:55:44,674 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:44,676 - DEBUG - Starting component System
2023-11-24 09:55:44,676 - DEBUG - Starting component Posthog
2023-11-24 09:55:44,676 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:44,683 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:44,683 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:44,685 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:45,144 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:46,714 - INFO - Use pytorch device: cpu
2023-11-24 09:55:46,716 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:48,888 - INFO - Use pytorch device: cpu
2023-11-24 09:55:48,888 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:50,881 - INFO - Use pytorch device: cpu
2023-11-24 09:55:50,885 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:50,888 - DEBUG - Starting component System
2023-11-24 09:55:50,888 - DEBUG - Starting component Posthog
2023-11-24 09:55:50,888 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:50,895 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:50,895 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:50,900 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 09:55:51,261 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:52,156 - INFO - Use pytorch device: cpu
2023-11-24 09:55:52,169 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:52,170 - DEBUG - Starting component System
2023-11-24 09:55:52,170 - DEBUG - Starting component Posthog
2023-11-24 09:55:52,170 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:52,173 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:52,173 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:52,190 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:52,191 - DEBUG - Starting component System
2023-11-24 09:55:52,191 - DEBUG - Starting component Posthog
2023-11-24 09:55:52,191 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:52,197 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:52,197 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:52,200 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:52,201 - DEBUG - Starting component System
2023-11-24 09:55:52,201 - DEBUG - Starting component Posthog
2023-11-24 09:55:52,201 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:52,204 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:52,204 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:52,207 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:52,209 - DEBUG - Starting component System
2023-11-24 09:55:52,209 - DEBUG - Starting component Posthog
2023-11-24 09:55:52,209 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:52,212 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:52,212 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:52,215 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 09:55:52,216 - DEBUG - Starting component System
2023-11-24 09:55:52,216 - DEBUG - Starting component Posthog
2023-11-24 09:55:52,216 - DEBUG - Starting component SqliteDB
2023-11-24 09:55:52,218 - DEBUG - Starting component LocalSegmentManager
2023-11-24 09:55:52,218 - DEBUG - Starting component SegmentAPI
2023-11-24 09:55:52,364 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 09:55:54,080 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:55:54,137 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:55:54,138 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:55:54,138 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 09:55:54,178 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 09:55:57,144 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:55:57,150 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2672 request_id=f7e5633222c628693b6bbf824fd7d049 response_code=200
2023-11-24 09:55:58,211 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:55:58,494 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:55:58,495 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:56:01,539 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:56:01,541 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2886 request_id=cfc0ae89cfc8d358acd369e27b599ecf response_code=200
2023-11-24 09:56:02,024 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:56:02,053 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:56:02,053 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:56:06,840 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:56:06,842 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4631 request_id=ca299fae75e6400c0c89b3a9659a6d28 response_code=200
2023-11-24 09:56:07,094 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:56:07,276 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:56:07,276 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 09:56:09,084 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:56:09,085 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1641 request_id=ce5d380b519b002ffdf3c56a5798b779 response_code=200
2023-11-24 09:56:09,313 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 09:56:09,359 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 09:56:09,359 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 09:56:15,675 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 09:56:15,676 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=5706 request_id=37a5f28422841bb0aad20e34abb8fa52 response_code=200
2023-11-24 09:56:15,700 - INFO - 0.7276811601761997
2023-11-24 09:56:15,710 - INFO - 0.7276811601761997
2023-11-24 09:56:15,710 - INFO - 0.7276811601761997
2023-11-24 09:56:15,711 - INFO - 0.7276811601761997
2023-11-24 09:56:15,711 - INFO - 0.7276811601761997
2023-11-24 09:56:15,839 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 09:56:15,852 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 09:56:16,025 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 09:56:16,028 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,029 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 09:56:16,029 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,029 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,029 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,029 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,030 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,031 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 09:56:16,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 09:56:16,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:56:16,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:56:16,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 09:56:16,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 09:56:16,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 09:56:16,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 09:56:16,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,052 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 09:56:16,053 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 10:00:16,158 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 10:00:16,171 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 10:00:16,174 - DEBUG - interactive is False
2023-11-24 10:00:16,174 - DEBUG - platform is darwin
2023-11-24 10:00:16,267 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 10:00:16,270 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 10:00:24,172 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:25,909 - INFO - Use pytorch device: cpu
2023-11-24 10:00:25,909 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:26,883 - INFO - Use pytorch device: cpu
2023-11-24 10:00:27,030 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:00:27,145 - DEBUG - Starting component System
2023-11-24 10:00:27,146 - DEBUG - Starting component Posthog
2023-11-24 10:00:27,146 - DEBUG - Starting component SqliteDB
2023-11-24 10:00:27,157 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:00:27,157 - DEBUG - Starting component SegmentAPI
2023-11-24 10:00:27,162 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:27,706 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 10:00:27,995 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:00:28,156 - INFO - Use pytorch device: cpu
2023-11-24 10:00:28,156 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:29,209 - INFO - Use pytorch device: cpu
2023-11-24 10:00:29,209 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:30,287 - INFO - Use pytorch device: cpu
2023-11-24 10:00:30,288 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:00:30,289 - DEBUG - Starting component System
2023-11-24 10:00:30,289 - DEBUG - Starting component Posthog
2023-11-24 10:00:30,289 - DEBUG - Starting component SqliteDB
2023-11-24 10:00:30,294 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:00:30,294 - DEBUG - Starting component SegmentAPI
2023-11-24 10:00:30,297 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:30,564 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:00:33,048 - INFO - Use pytorch device: cpu
2023-11-24 10:00:33,049 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:34,118 - INFO - Use pytorch device: cpu
2023-11-24 10:00:34,118 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:36,733 - INFO - Use pytorch device: cpu
2023-11-24 10:00:36,755 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:00:36,760 - DEBUG - Starting component System
2023-11-24 10:00:36,761 - DEBUG - Starting component Posthog
2023-11-24 10:00:36,761 - DEBUG - Starting component SqliteDB
2023-11-24 10:00:36,790 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:00:36,790 - DEBUG - Starting component SegmentAPI
2023-11-24 10:00:36,799 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:37,212 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:00:40,787 - INFO - Use pytorch device: cpu
2023-11-24 10:00:40,801 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:45,983 - INFO - Use pytorch device: cpu
2023-11-24 10:00:45,984 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:47,533 - INFO - Use pytorch device: cpu
2023-11-24 10:00:47,546 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:00:47,563 - DEBUG - Starting component System
2023-11-24 10:00:47,563 - DEBUG - Starting component Posthog
2023-11-24 10:00:47,563 - DEBUG - Starting component SqliteDB
2023-11-24 10:00:47,572 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:00:47,573 - DEBUG - Starting component SegmentAPI
2023-11-24 10:00:47,581 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:47,924 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:00:51,180 - INFO - Use pytorch device: cpu
2023-11-24 10:00:51,181 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:53,601 - INFO - Use pytorch device: cpu
2023-11-24 10:00:53,602 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:56,869 - INFO - Use pytorch device: cpu
2023-11-24 10:00:56,874 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:00:56,876 - DEBUG - Starting component System
2023-11-24 10:00:56,877 - DEBUG - Starting component Posthog
2023-11-24 10:00:56,877 - DEBUG - Starting component SqliteDB
2023-11-24 10:00:56,888 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:00:56,888 - DEBUG - Starting component SegmentAPI
2023-11-24 10:00:56,894 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:00:57,072 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:01:00,318 - INFO - Use pytorch device: cpu
2023-11-24 10:01:00,331 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:01:00,333 - DEBUG - Starting component System
2023-11-24 10:01:00,333 - DEBUG - Starting component Posthog
2023-11-24 10:01:00,333 - DEBUG - Starting component SqliteDB
2023-11-24 10:01:00,340 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:01:00,340 - DEBUG - Starting component SegmentAPI
2023-11-24 10:01:00,362 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:01:00,363 - DEBUG - Starting component System
2023-11-24 10:01:00,364 - DEBUG - Starting component Posthog
2023-11-24 10:01:00,364 - DEBUG - Starting component SqliteDB
2023-11-24 10:01:00,371 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:01:00,371 - DEBUG - Starting component SegmentAPI
2023-11-24 10:01:00,375 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:01:00,376 - DEBUG - Starting component System
2023-11-24 10:01:00,377 - DEBUG - Starting component Posthog
2023-11-24 10:01:00,377 - DEBUG - Starting component SqliteDB
2023-11-24 10:01:00,381 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:01:00,382 - DEBUG - Starting component SegmentAPI
2023-11-24 10:01:00,386 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:01:00,389 - DEBUG - Starting component System
2023-11-24 10:01:00,389 - DEBUG - Starting component Posthog
2023-11-24 10:01:00,389 - DEBUG - Starting component SqliteDB
2023-11-24 10:01:00,394 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:01:00,394 - DEBUG - Starting component SegmentAPI
2023-11-24 10:01:00,398 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:01:00,399 - DEBUG - Starting component System
2023-11-24 10:01:00,399 - DEBUG - Starting component Posthog
2023-11-24 10:01:00,399 - DEBUG - Starting component SqliteDB
2023-11-24 10:01:00,402 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:01:00,402 - DEBUG - Starting component SegmentAPI
2023-11-24 10:01:00,777 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:01:02,013 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:01:02,094 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:01:02,094 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:01:02,096 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 10:01:02,168 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 10:01:05,536 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:01:05,541 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2984 request_id=4bd2135b9f6b1bbd67e9d4bd05ec04e9 response_code=200
2023-11-24 10:01:07,771 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:01:08,171 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:01:08,171 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:01:11,578 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:01:11,581 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3263 request_id=15f39cacb2872924c0066e70444619a5 response_code=200
2023-11-24 10:01:12,146 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:01:12,191 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:01:12,191 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:01:14,236 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:01:14,238 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1872 request_id=cb8ae864192c7918591f9d2502af0791 response_code=200
2023-11-24 10:01:15,396 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:01:16,054 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:01:16,056 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:02:38,392 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:02:38,393 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:02:38,450 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-24 10:02:40,221 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:02:40,230 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1392 request_id=5e520cf910b3d8fabbf5edd3b05423e2 response_code=200
2023-11-24 10:02:40,367 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:02:40,384 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:02:42,989 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:02:43,035 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2465 request_id=47b5fba1dbdd83d15f98a1af649467df response_code=200
2023-11-24 10:02:43,159 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:02:43,160 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:02:46,727 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:02:46,728 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3438 request_id=0a42aafeade06e2bea41a990080ba546 response_code=200
2023-11-24 10:02:46,985 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:02:46,985 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:02:48,830 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:02:48,830 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1711 request_id=1f44fcadd915bb9b3db9dc9de7f2ef60 response_code=200
2023-11-24 10:02:50,094 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:02:50,148 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:02:50,148 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:02:51,688 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:02:51,701 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1411 request_id=edaee36b46f6d3c83d30cd4ed61c2748 response_code=200
2023-11-24 10:02:51,707 - INFO - 0.7475288574615049
2023-11-24 10:02:51,714 - INFO - 0.7475288574615049
2023-11-24 10:02:51,715 - INFO - 0.7475288574615049
2023-11-24 10:02:51,715 - INFO - 0.7475288574615049
2023-11-24 10:02:51,716 - INFO - 0.7475288574615049
2023-11-24 10:02:51,741 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:02:51,743 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:02:51,768 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 10:02:51,768 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,768 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,769 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,770 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,771 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,772 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,773 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,773 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 10:02:51,773 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:02:51,773 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,774 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,774 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,774 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,774 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,775 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,776 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,776 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:02:51,776 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,776 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,776 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,777 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,778 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,779 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,780 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 10:02:51,781 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,782 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,783 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,784 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,785 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,786 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,787 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,788 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,789 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,790 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,791 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,792 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,792 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,792 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,792 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,792 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,793 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,793 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,793 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 10:02:51,793 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,794 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,794 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,795 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,795 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 10:02:51,795 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,795 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,795 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,796 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,797 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,798 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,799 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,800 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,801 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,802 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,803 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,804 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,805 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,806 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,807 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,808 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,809 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,810 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:02:51,811 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,812 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,812 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:02:51,812 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 10:03:44,356 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 10:03:44,365 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 10:03:44,366 - DEBUG - interactive is False
2023-11-24 10:03:44,366 - DEBUG - platform is darwin
2023-11-24 10:03:44,437 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 10:03:44,440 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 10:03:53,347 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:03:55,173 - INFO - Use pytorch device: cpu
2023-11-24 10:03:55,173 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:03:56,221 - INFO - Use pytorch device: cpu
2023-11-24 10:03:56,373 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:03:56,482 - DEBUG - Starting component System
2023-11-24 10:03:56,482 - DEBUG - Starting component Posthog
2023-11-24 10:03:56,482 - DEBUG - Starting component SqliteDB
2023-11-24 10:03:56,490 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:03:56,490 - DEBUG - Starting component SegmentAPI
2023-11-24 10:03:56,495 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:03:57,026 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 10:03:57,237 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:03:57,798 - INFO - Use pytorch device: cpu
2023-11-24 10:03:57,799 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:03:58,928 - INFO - Use pytorch device: cpu
2023-11-24 10:03:58,929 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:01,456 - INFO - Use pytorch device: cpu
2023-11-24 10:04:01,461 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:01,468 - DEBUG - Starting component System
2023-11-24 10:04:01,468 - DEBUG - Starting component Posthog
2023-11-24 10:04:01,468 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:01,484 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:01,485 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:01,500 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:01,833 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:04:03,181 - INFO - Use pytorch device: cpu
2023-11-24 10:04:03,182 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:05,624 - INFO - Use pytorch device: cpu
2023-11-24 10:04:05,625 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:07,090 - INFO - Use pytorch device: cpu
2023-11-24 10:04:07,098 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:07,101 - DEBUG - Starting component System
2023-11-24 10:04:07,101 - DEBUG - Starting component Posthog
2023-11-24 10:04:07,102 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:07,116 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:07,116 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:07,121 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:07,413 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:04:11,339 - INFO - Use pytorch device: cpu
2023-11-24 10:04:11,341 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:14,484 - INFO - Use pytorch device: cpu
2023-11-24 10:04:14,487 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:18,432 - INFO - Use pytorch device: cpu
2023-11-24 10:04:18,445 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:18,450 - DEBUG - Starting component System
2023-11-24 10:04:18,450 - DEBUG - Starting component Posthog
2023-11-24 10:04:18,451 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:18,463 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:18,463 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:18,471 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:18,572 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:04:21,260 - INFO - Use pytorch device: cpu
2023-11-24 10:04:21,267 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:23,303 - INFO - Use pytorch device: cpu
2023-11-24 10:04:23,304 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:25,728 - INFO - Use pytorch device: cpu
2023-11-24 10:04:25,731 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:25,732 - DEBUG - Starting component System
2023-11-24 10:04:25,732 - DEBUG - Starting component Posthog
2023-11-24 10:04:25,733 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:25,743 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:25,743 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:25,747 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:04:26,154 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:04:28,712 - INFO - Use pytorch device: cpu
2023-11-24 10:04:28,729 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:28,732 - DEBUG - Starting component System
2023-11-24 10:04:28,732 - DEBUG - Starting component Posthog
2023-11-24 10:04:28,732 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:28,749 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:28,749 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:28,773 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:28,775 - DEBUG - Starting component System
2023-11-24 10:04:28,775 - DEBUG - Starting component Posthog
2023-11-24 10:04:28,775 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:28,781 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:28,781 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:28,790 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:28,791 - DEBUG - Starting component System
2023-11-24 10:04:28,792 - DEBUG - Starting component Posthog
2023-11-24 10:04:28,792 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:28,796 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:28,796 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:28,799 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:28,802 - DEBUG - Starting component System
2023-11-24 10:04:28,802 - DEBUG - Starting component Posthog
2023-11-24 10:04:28,802 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:28,807 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:28,807 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:28,811 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:04:28,811 - DEBUG - Starting component System
2023-11-24 10:04:28,812 - DEBUG - Starting component Posthog
2023-11-24 10:04:28,812 - DEBUG - Starting component SqliteDB
2023-11-24 10:04:28,814 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:04:28,814 - DEBUG - Starting component SegmentAPI
2023-11-24 10:04:29,659 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:04:32,509 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:04:32,633 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:04:32,634 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:04:32,636 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 10:04:32,676 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 10:04:35,857 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:04:35,861 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2709 request_id=7e9462e556cfdcfd3120337556980562 response_code=200
2023-11-24 10:04:36,809 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:04:37,194 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:04:37,195 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:04:39,648 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:04:39,648 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2320 request_id=11c1a88b4da349647f016c6ce00e8e23 response_code=200
2023-11-24 10:04:40,158 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:04:40,210 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:04:40,210 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:04:46,503 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:04:46,504 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6159 request_id=64944833cce54741f59c98b236dcc584 response_code=200
2023-11-24 10:04:48,582 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:04:50,407 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:04:50,408 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:04:53,618 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:04:53,619 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3075 request_id=5e1212c7b3c585c57939630343168d2d response_code=200
2023-11-24 10:04:54,197 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:04:54,283 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:04:54,284 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:04:54,924 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:04:54,925 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=452 request_id=5fb0e9422104ba033385457cd623a182 response_code=200
2023-11-24 10:04:54,957 - INFO - 0.858796035621815
2023-11-24 10:04:54,961 - INFO - 0.858796035621815
2023-11-24 10:04:54,962 - INFO - 0.858796035621815
2023-11-24 10:04:54,962 - INFO - 0.858796035621815
2023-11-24 10:04:54,962 - INFO - 0.858796035621815
2023-11-24 10:04:55,091 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:04:55,102 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:04:55,220 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 10:04:55,227 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,227 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,228 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,229 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,230 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 10:04:55,230 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,230 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,230 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,231 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 10:04:55,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,232 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,233 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,234 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,235 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,236 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,237 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,238 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 10:04:55,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 10:04:55,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,239 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 10:04:55,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,240 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,241 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,242 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,243 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,244 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:04:55,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,245 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,247 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,248 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,249 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,250 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,251 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,252 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:04:55,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,253 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,254 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,255 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,256 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,257 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,258 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,259 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:04:55,260 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,261 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,262 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,263 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,264 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:04:55,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 10:04:55,265 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,266 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,266 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:04:55,266 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,266 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,266 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,267 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,268 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,269 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,270 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:04:55,271 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:04:55,272 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,273 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,274 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,275 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,276 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,277 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,277 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:04:55,277 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,277 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,277 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:04:55,277 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 10:15:36,057 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 10:15:36,068 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 10:15:36,071 - DEBUG - interactive is False
2023-11-24 10:15:36,071 - DEBUG - platform is darwin
2023-11-24 10:15:36,167 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 10:15:36,171 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 10:15:45,064 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:47,053 - INFO - Use pytorch device: cpu
2023-11-24 10:15:47,054 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:48,093 - INFO - Use pytorch device: cpu
2023-11-24 10:15:48,247 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:15:48,402 - DEBUG - Starting component System
2023-11-24 10:15:48,403 - DEBUG - Starting component Posthog
2023-11-24 10:15:48,403 - DEBUG - Starting component SqliteDB
2023-11-24 10:15:48,416 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:15:48,417 - DEBUG - Starting component SegmentAPI
2023-11-24 10:15:48,424 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:48,958 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 10:15:49,091 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:15:50,137 - INFO - Use pytorch device: cpu
2023-11-24 10:15:50,138 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:51,268 - INFO - Use pytorch device: cpu
2023-11-24 10:15:51,268 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:52,863 - INFO - Use pytorch device: cpu
2023-11-24 10:15:52,866 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:15:52,868 - DEBUG - Starting component System
2023-11-24 10:15:52,868 - DEBUG - Starting component Posthog
2023-11-24 10:15:52,868 - DEBUG - Starting component SqliteDB
2023-11-24 10:15:52,872 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:15:52,873 - DEBUG - Starting component SegmentAPI
2023-11-24 10:15:52,876 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:53,182 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:15:55,238 - INFO - Use pytorch device: cpu
2023-11-24 10:15:55,238 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:56,303 - INFO - Use pytorch device: cpu
2023-11-24 10:15:56,305 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:57,465 - INFO - Use pytorch device: cpu
2023-11-24 10:15:57,467 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:15:57,468 - DEBUG - Starting component System
2023-11-24 10:15:57,468 - DEBUG - Starting component Posthog
2023-11-24 10:15:57,468 - DEBUG - Starting component SqliteDB
2023-11-24 10:15:57,475 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:15:57,475 - DEBUG - Starting component SegmentAPI
2023-11-24 10:15:57,477 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:15:57,941 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:15:59,987 - INFO - Use pytorch device: cpu
2023-11-24 10:15:59,990 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:01,199 - INFO - Use pytorch device: cpu
2023-11-24 10:16:01,202 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:02,377 - INFO - Use pytorch device: cpu
2023-11-24 10:16:02,400 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:02,415 - DEBUG - Starting component System
2023-11-24 10:16:02,416 - DEBUG - Starting component Posthog
2023-11-24 10:16:02,416 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:02,425 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:02,425 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:02,433 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:02,562 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:16:04,553 - INFO - Use pytorch device: cpu
2023-11-24 10:16:04,557 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:05,760 - INFO - Use pytorch device: cpu
2023-11-24 10:16:05,760 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:08,350 - INFO - Use pytorch device: cpu
2023-11-24 10:16:08,361 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:08,364 - DEBUG - Starting component System
2023-11-24 10:16:08,364 - DEBUG - Starting component Posthog
2023-11-24 10:16:08,364 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:08,374 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:08,374 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:08,378 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:16:08,718 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:16:10,300 - INFO - Use pytorch device: cpu
2023-11-24 10:16:10,312 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:10,313 - DEBUG - Starting component System
2023-11-24 10:16:10,313 - DEBUG - Starting component Posthog
2023-11-24 10:16:10,313 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:10,316 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:10,316 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:10,329 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:10,330 - DEBUG - Starting component System
2023-11-24 10:16:10,330 - DEBUG - Starting component Posthog
2023-11-24 10:16:10,330 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:10,333 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:10,333 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:10,336 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:10,336 - DEBUG - Starting component System
2023-11-24 10:16:10,336 - DEBUG - Starting component Posthog
2023-11-24 10:16:10,336 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:10,340 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:10,340 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:10,344 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:10,345 - DEBUG - Starting component System
2023-11-24 10:16:10,345 - DEBUG - Starting component Posthog
2023-11-24 10:16:10,345 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:10,348 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:10,348 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:10,351 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:16:10,352 - DEBUG - Starting component System
2023-11-24 10:16:10,352 - DEBUG - Starting component Posthog
2023-11-24 10:16:10,352 - DEBUG - Starting component SqliteDB
2023-11-24 10:16:10,355 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:16:10,355 - DEBUG - Starting component SegmentAPI
2023-11-24 10:16:10,870 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:16:13,869 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:16:13,989 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:16:13,989 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:16:13,992 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 10:16:14,045 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 10:16:16,356 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:16:16,362 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1923 request_id=0e61f96e91c8b756055724f87c30f0b4 response_code=200
2023-11-24 10:16:17,533 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:16:18,015 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:16:18,015 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:16:19,426 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:16:19,426 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1243 request_id=80bdafe2bcf3cb7010146ab0f0aa1d79 response_code=200
2023-11-24 10:16:19,967 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:16:20,007 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:16:20,007 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:17:17,420 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:17:17,421 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:17:17,428 - DEBUG - Starting new HTTPS connection (2): api.openai.com:443
2023-11-24 10:17:19,537 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:17:19,538 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1786 request_id=000c5768b87273257d920713e44d7151 response_code=200
2023-11-24 10:17:19,975 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:17:19,975 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:17:23,015 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:17:23,016 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2842 request_id=54aa7b9cc23f2b4093e3b45bc7f43b39 response_code=200
2023-11-24 10:17:23,142 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:17:23,142 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:17:25,984 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:17:25,986 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2546 request_id=d70d28051e92f7851d97ed3ca662b679 response_code=200
2023-11-24 10:17:26,360 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:17:26,656 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:17:26,656 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:17:28,647 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:17:28,648 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1725 request_id=659cf7424c591006b38c81b8c9c219d0 response_code=200
2023-11-24 10:17:29,058 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:17:29,105 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:17:29,105 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:17:33,049 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:17:33,052 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3728 request_id=a7ff2e213ae7571872e5247f23eac453 response_code=200
2023-11-24 10:17:33,057 - INFO - 0.919692266787451
2023-11-24 10:17:33,063 - INFO - 0.919692266787451
2023-11-24 10:17:33,063 - INFO - 0.919692266787451
2023-11-24 10:17:33,064 - INFO - 0.919692266787451
2023-11-24 10:17:33,064 - INFO - 0.919692266787451
2023-11-24 10:17:33,095 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:17:33,096 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:17:33,120 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 10:17:33,121 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,121 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 10:17:33,121 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,121 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,121 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,122 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,122 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,122 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,122 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,123 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,123 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,123 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,123 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,124 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,125 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:17:33,126 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,127 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,127 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,128 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 10:17:33,129 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,130 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,131 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,132 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,133 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 10:17:33,133 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,133 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,133 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,134 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,134 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,134 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,134 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,134 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,135 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,136 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,137 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 10:17:33,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:17:33,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 10:17:33,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 10:17:33,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:17:33,166 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-24 10:18:52,787 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-24 10:18:52,796 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-24 10:18:52,799 - DEBUG - interactive is False
2023-11-24 10:18:52,799 - DEBUG - platform is darwin
2023-11-24 10:18:52,898 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-24 10:18:52,902 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-24 10:19:00,214 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:01,706 - INFO - Use pytorch device: cpu
2023-11-24 10:19:01,707 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:02,659 - INFO - Use pytorch device: cpu
2023-11-24 10:19:02,792 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:02,935 - DEBUG - Starting component System
2023-11-24 10:19:02,935 - DEBUG - Starting component Posthog
2023-11-24 10:19:02,936 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:02,946 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:02,946 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:02,952 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:03,480 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-24 10:19:03,603 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:03,963 - INFO - Use pytorch device: cpu
2023-11-24 10:19:03,963 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:04,944 - INFO - Use pytorch device: cpu
2023-11-24 10:19:04,944 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:05,923 - INFO - Use pytorch device: cpu
2023-11-24 10:19:05,924 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:05,925 - DEBUG - Starting component System
2023-11-24 10:19:05,925 - DEBUG - Starting component Posthog
2023-11-24 10:19:05,925 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:05,930 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:05,930 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:05,932 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:06,169 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:07,073 - INFO - Use pytorch device: cpu
2023-11-24 10:19:07,074 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:09,058 - INFO - Use pytorch device: cpu
2023-11-24 10:19:09,059 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:10,135 - INFO - Use pytorch device: cpu
2023-11-24 10:19:10,137 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:10,139 - DEBUG - Starting component System
2023-11-24 10:19:10,139 - DEBUG - Starting component Posthog
2023-11-24 10:19:10,139 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:10,143 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:10,143 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:10,147 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:10,275 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:12,337 - INFO - Use pytorch device: cpu
2023-11-24 10:19:12,340 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:13,460 - INFO - Use pytorch device: cpu
2023-11-24 10:19:13,460 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:14,592 - INFO - Use pytorch device: cpu
2023-11-24 10:19:14,593 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:14,594 - DEBUG - Starting component System
2023-11-24 10:19:14,594 - DEBUG - Starting component Posthog
2023-11-24 10:19:14,594 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:14,598 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:14,598 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:14,600 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:14,848 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:16,781 - INFO - Use pytorch device: cpu
2023-11-24 10:19:16,782 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:17,834 - INFO - Use pytorch device: cpu
2023-11-24 10:19:17,834 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:20,026 - INFO - Use pytorch device: cpu
2023-11-24 10:19:20,055 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:20,060 - DEBUG - Starting component System
2023-11-24 10:19:20,060 - DEBUG - Starting component Posthog
2023-11-24 10:19:20,060 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:20,083 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:20,083 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:20,089 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-24 10:19:20,611 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:22,460 - INFO - Use pytorch device: cpu
2023-11-24 10:19:22,475 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:22,476 - DEBUG - Starting component System
2023-11-24 10:19:22,476 - DEBUG - Starting component Posthog
2023-11-24 10:19:22,476 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:22,480 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:22,480 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:22,497 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:22,498 - DEBUG - Starting component System
2023-11-24 10:19:22,498 - DEBUG - Starting component Posthog
2023-11-24 10:19:22,498 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:22,502 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:22,502 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:22,506 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:22,507 - DEBUG - Starting component System
2023-11-24 10:19:22,508 - DEBUG - Starting component Posthog
2023-11-24 10:19:22,508 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:22,511 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:22,511 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:22,516 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:22,519 - DEBUG - Starting component System
2023-11-24 10:19:22,519 - DEBUG - Starting component Posthog
2023-11-24 10:19:22,519 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:22,523 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:22,523 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:22,526 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-24 10:19:22,527 - DEBUG - Starting component System
2023-11-24 10:19:22,527 - DEBUG - Starting component Posthog
2023-11-24 10:19:22,527 - DEBUG - Starting component SqliteDB
2023-11-24 10:19:22,529 - DEBUG - Starting component LocalSegmentManager
2023-11-24 10:19:22,529 - DEBUG - Starting component SegmentAPI
2023-11-24 10:19:22,697 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-24 10:19:24,205 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:19:24,298 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:19:24,298 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:19:24,299 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-24 10:19:24,352 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-24 10:19:26,302 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:19:26,308 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1539 request_id=d5433260d5d25b957e209b49ecf641d0 response_code=200
2023-11-24 10:19:28,373 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:19:29,545 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:19:29,546 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:19:31,446 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:19:31,448 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1758 request_id=66a93df535e6a438ad9a831d22720b10 response_code=200
2023-11-24 10:19:32,432 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:19:32,485 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:19:32,485 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:19:34,082 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:19:34,084 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1386 request_id=6699caf6557fccf4da5a8e6f111a77ce response_code=200
2023-11-24 10:19:34,676 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:19:35,023 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:19:35,024 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-24 10:19:37,127 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:19:37,129 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1716 request_id=b275079a2592de4173dcf12c2c7ee7cd response_code=200
2023-11-24 10:19:37,543 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-24 10:19:37,620 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-24 10:19:37,621 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-24 10:19:39,915 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-24 10:19:39,917 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2100 request_id=975fa62c029a3e16461d90795405c724 response_code=200
2023-11-24 10:19:39,933 - INFO - 1.391200229644887
2023-11-24 10:19:39,938 - INFO - 1.391200229644887
2023-11-24 10:19:39,939 - INFO - 1.391200229644887
2023-11-24 10:19:39,939 - INFO - 1.391200229644887
2023-11-24 10:19:39,940 - INFO - 1.391200229644887
2023-11-24 10:19:40,031 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:19:40,039 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-24 10:19:40,125 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-24 10:19:40,132 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,133 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-24 10:19:40,133 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,133 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,134 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,135 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,136 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,137 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,138 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,138 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-24 10:19:40,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:19:40,138 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,139 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,140 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,141 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,142 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,143 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-24 10:19:40,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,144 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:19:40,145 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,146 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,147 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-24 10:19:40,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:19:40,148 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,149 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,150 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,151 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-24 10:19:40,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,152 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:19:40,153 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,154 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,155 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,156 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:19:40,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:19:40,157 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,158 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:19:40,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,159 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-24 10:19:40,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:19:40,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:19:40,160 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,161 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,162 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,163 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,164 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,165 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-24 10:19:40,166 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,167 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,167 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,168 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,168 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-24 10:19:40,168 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,168 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:19:40,169 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,170 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,171 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,172 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,173 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,173 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-24 10:19:40,173 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,173 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-24 10:19:40,173 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,174 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,174 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-24 10:19:40,174 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,174 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,174 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,175 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,176 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,176 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,176 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,177 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,177 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,177 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,178 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,179 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,180 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,180 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,180 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,180 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,181 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,181 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,181 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,181 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,182 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,183 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,183 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,183 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,183 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-24 10:19:40,184 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,185 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,186 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-24 10:19:40,187 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,188 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,189 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-24 10:19:40,189 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,189 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,189 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-24 10:19:40,189 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 09:33:17,308 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:33:17,322 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:33:17,325 - DEBUG - interactive is False
2023-11-25 09:33:17,326 - DEBUG - platform is darwin
2023-11-25 09:33:17,420 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:33:17,423 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:35:26,133 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:35:26,138 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:35:26,139 - DEBUG - interactive is False
2023-11-25 09:35:26,139 - DEBUG - platform is darwin
2023-11-25 09:35:26,205 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:35:26,207 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:37:18,137 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:37:18,143 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:37:18,144 - DEBUG - interactive is False
2023-11-25 09:37:18,144 - DEBUG - platform is darwin
2023-11-25 09:37:18,193 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:37:18,195 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:38:59,615 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:38:59,619 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:38:59,621 - DEBUG - interactive is False
2023-11-25 09:38:59,621 - DEBUG - platform is darwin
2023-11-25 09:38:59,670 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:38:59,671 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:39:46,317 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:39:46,321 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:39:46,323 - DEBUG - interactive is False
2023-11-25 09:39:46,323 - DEBUG - platform is darwin
2023-11-25 09:39:46,373 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:39:46,375 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:41:48,226 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:41:48,232 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:41:48,233 - DEBUG - interactive is False
2023-11-25 09:41:48,233 - DEBUG - platform is darwin
2023-11-25 09:41:48,283 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:41:48,285 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:42:54,874 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:42:57,301 - INFO - Use pytorch device: cpu
2023-11-25 09:42:57,304 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:42:58,551 - INFO - Use pytorch device: cpu
2023-11-25 09:42:58,813 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:42:58,969 - DEBUG - Starting component System
2023-11-25 09:42:58,969 - DEBUG - Starting component Posthog
2023-11-25 09:42:58,969 - DEBUG - Starting component SqliteDB
2023-11-25 09:42:58,981 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:42:58,981 - DEBUG - Starting component SegmentAPI
2023-11-25 09:42:58,989 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:42:59,526 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 09:43:00,193 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:00,251 - INFO - Use pytorch device: cpu
2023-11-25 09:43:00,252 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:02,353 - INFO - Use pytorch device: cpu
2023-11-25 09:43:02,354 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:03,540 - INFO - Use pytorch device: cpu
2023-11-25 09:43:03,543 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:03,545 - DEBUG - Starting component System
2023-11-25 09:43:03,545 - DEBUG - Starting component Posthog
2023-11-25 09:43:03,545 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:03,550 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:03,550 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:03,554 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:03,822 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:06,439 - INFO - Use pytorch device: cpu
2023-11-25 09:43:06,443 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:07,650 - INFO - Use pytorch device: cpu
2023-11-25 09:43:07,650 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:10,166 - INFO - Use pytorch device: cpu
2023-11-25 09:43:10,170 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:10,173 - DEBUG - Starting component System
2023-11-25 09:43:10,173 - DEBUG - Starting component Posthog
2023-11-25 09:43:10,173 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:10,178 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:10,178 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:10,181 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:10,646 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:11,311 - INFO - Use pytorch device: cpu
2023-11-25 09:43:11,311 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:13,566 - INFO - Use pytorch device: cpu
2023-11-25 09:43:13,567 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:16,161 - INFO - Use pytorch device: cpu
2023-11-25 09:43:16,167 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:16,169 - DEBUG - Starting component System
2023-11-25 09:43:16,169 - DEBUG - Starting component Posthog
2023-11-25 09:43:16,169 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:16,177 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:16,177 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:16,180 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:16,286 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:22,900 - INFO - Use pytorch device: cpu
2023-11-25 09:43:22,916 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:26,387 - INFO - Use pytorch device: cpu
2023-11-25 09:43:26,389 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:29,495 - INFO - Use pytorch device: cpu
2023-11-25 09:43:29,507 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:29,512 - DEBUG - Starting component System
2023-11-25 09:43:29,512 - DEBUG - Starting component Posthog
2023-11-25 09:43:29,513 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:29,521 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:29,521 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:29,528 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:43:29,974 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:33,096 - INFO - Use pytorch device: cpu
2023-11-25 09:43:33,107 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:33,108 - DEBUG - Starting component System
2023-11-25 09:43:33,108 - DEBUG - Starting component Posthog
2023-11-25 09:43:33,108 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:33,113 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:33,113 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:33,124 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:33,125 - DEBUG - Starting component System
2023-11-25 09:43:33,125 - DEBUG - Starting component Posthog
2023-11-25 09:43:33,125 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:33,129 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:33,129 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:33,132 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:33,133 - DEBUG - Starting component System
2023-11-25 09:43:33,133 - DEBUG - Starting component Posthog
2023-11-25 09:43:33,133 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:33,137 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:33,138 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:33,141 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:33,142 - DEBUG - Starting component System
2023-11-25 09:43:33,142 - DEBUG - Starting component Posthog
2023-11-25 09:43:33,142 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:33,147 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:33,147 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:33,150 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:43:33,151 - DEBUG - Starting component System
2023-11-25 09:43:33,151 - DEBUG - Starting component Posthog
2023-11-25 09:43:33,151 - DEBUG - Starting component SqliteDB
2023-11-25 09:43:33,154 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:43:33,154 - DEBUG - Starting component SegmentAPI
2023-11-25 09:43:33,786 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:43:35,872 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:43:35,999 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:43:36,000 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:43:36,002 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 09:43:36,061 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 09:43:38,402 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:43:38,424 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1739 request_id=a3877ad4d9a313da951359a89647bd76 response_code=200
2023-11-25 09:43:39,110 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:43:39,435 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:43:39,435 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:43:41,145 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:43:41,146 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1576 request_id=dc605e6c9dbbb25f0f7f6e1799d0ae79 response_code=200
2023-11-25 09:43:41,921 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:43:41,959 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:43:41,959 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 09:43:44,543 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:43:44,545 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2287 request_id=6a3a96d2c2a27df55fa3a84964611a27 response_code=200
2023-11-25 09:43:44,949 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:43:45,251 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:43:45,252 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:43:46,077 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:43:46,078 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=597 request_id=053c06e78dce6254dc2aebf3f1aa2b36 response_code=200
2023-11-25 09:43:46,206 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:43:46,260 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:43:46,260 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 09:43:46,905 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:43:46,906 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=480 request_id=82c2d1095dda9c7a3f4ecff0ce325ded response_code=200
2023-11-25 09:47:50,591 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:47:50,599 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:47:50,601 - DEBUG - interactive is False
2023-11-25 09:47:50,601 - DEBUG - platform is darwin
2023-11-25 09:47:50,674 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:47:50,677 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:47:57,194 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:47:58,841 - INFO - Use pytorch device: cpu
2023-11-25 09:47:58,842 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:47:59,935 - INFO - Use pytorch device: cpu
2023-11-25 09:48:00,071 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:48:00,188 - DEBUG - Starting component System
2023-11-25 09:48:00,189 - DEBUG - Starting component Posthog
2023-11-25 09:48:00,189 - DEBUG - Starting component SqliteDB
2023-11-25 09:48:00,197 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:48:00,197 - DEBUG - Starting component SegmentAPI
2023-11-25 09:48:00,202 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:48:00,738 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 09:48:00,910 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:48:01,351 - INFO - Use pytorch device: cpu
2023-11-25 09:48:01,352 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:48:02,516 - INFO - Use pytorch device: cpu
2023-11-25 09:48:02,516 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:48:03,719 - INFO - Use pytorch device: cpu
2023-11-25 09:48:03,722 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:48:03,722 - DEBUG - Starting component System
2023-11-25 09:48:03,723 - DEBUG - Starting component Posthog
2023-11-25 09:48:03,723 - DEBUG - Starting component SqliteDB
2023-11-25 09:48:03,730 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:48:03,730 - DEBUG - Starting component SegmentAPI
2023-11-25 09:48:03,732 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:48:03,989 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:48:06,603 - INFO - Use pytorch device: cpu
2023-11-25 09:48:06,605 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:48:06,606 - DEBUG - Starting component System
2023-11-25 09:48:06,606 - DEBUG - Starting component Posthog
2023-11-25 09:48:06,606 - DEBUG - Starting component SqliteDB
2023-11-25 09:48:06,609 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:48:06,610 - DEBUG - Starting component SegmentAPI
2023-11-25 09:48:06,613 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:48:06,614 - DEBUG - Starting component System
2023-11-25 09:48:06,614 - DEBUG - Starting component Posthog
2023-11-25 09:48:06,614 - DEBUG - Starting component SqliteDB
2023-11-25 09:48:06,616 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:48:06,616 - DEBUG - Starting component SegmentAPI
2023-11-25 09:48:06,757 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:48:07,451 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:48:07,510 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:48:07,510 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:48:07,511 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 09:48:07,563 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 09:48:10,568 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:48:10,571 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2504 request_id=4104f639bb41483f42acf19ea67c6360 response_code=200
2023-11-25 09:48:10,723 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:48:11,017 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:48:11,017 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:48:12,616 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:48:12,618 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1374 request_id=086447bb55c0d4ecd6a233c68476c5dd response_code=200
2023-11-25 09:52:28,044 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:52:28,050 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:52:28,052 - DEBUG - interactive is False
2023-11-25 09:52:28,052 - DEBUG - platform is darwin
2023-11-25 09:52:28,115 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:52:28,118 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:52:32,429 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:33,928 - INFO - Use pytorch device: cpu
2023-11-25 09:52:33,928 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:34,975 - INFO - Use pytorch device: cpu
2023-11-25 09:52:35,079 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:52:35,190 - DEBUG - Starting component System
2023-11-25 09:52:35,194 - DEBUG - Starting component Posthog
2023-11-25 09:52:35,195 - DEBUG - Starting component SqliteDB
2023-11-25 09:52:35,199 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:52:35,213 - DEBUG - Starting component SegmentAPI
2023-11-25 09:52:35,217 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:35,761 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 09:52:36,113 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:52:36,229 - INFO - Use pytorch device: cpu
2023-11-25 09:52:36,229 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:37,283 - INFO - Use pytorch device: cpu
2023-11-25 09:52:37,284 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:38,528 - INFO - Use pytorch device: cpu
2023-11-25 09:52:38,529 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:52:38,530 - DEBUG - Starting component System
2023-11-25 09:52:38,530 - DEBUG - Starting component Posthog
2023-11-25 09:52:38,530 - DEBUG - Starting component SqliteDB
2023-11-25 09:52:38,536 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:52:38,536 - DEBUG - Starting component SegmentAPI
2023-11-25 09:52:38,538 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:52:38,691 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:52:41,919 - INFO - Use pytorch device: cpu
2023-11-25 09:52:41,924 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:52:41,925 - DEBUG - Starting component System
2023-11-25 09:52:41,925 - DEBUG - Starting component Posthog
2023-11-25 09:52:41,925 - DEBUG - Starting component SqliteDB
2023-11-25 09:52:41,928 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:52:41,929 - DEBUG - Starting component SegmentAPI
2023-11-25 09:52:41,931 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:52:41,932 - DEBUG - Starting component System
2023-11-25 09:52:41,932 - DEBUG - Starting component Posthog
2023-11-25 09:52:41,932 - DEBUG - Starting component SqliteDB
2023-11-25 09:52:41,934 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:52:41,934 - DEBUG - Starting component SegmentAPI
2023-11-25 09:52:42,302 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:52:42,348 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:52:42,405 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:52:42,405 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:52:42,405 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 09:52:42,451 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 09:52:44,391 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:52:44,394 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1468 request_id=17b21fd0adf2613953b9eecb91d4a341 response_code=200
2023-11-25 09:52:44,524 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:52:44,792 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:52:44,793 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:52:45,785 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:52:45,786 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=830 request_id=2a18d500b795b29f883509b04c189416 response_code=200
2023-11-25 09:54:29,507 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:54:29,513 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:54:29,514 - DEBUG - interactive is False
2023-11-25 09:54:29,514 - DEBUG - platform is darwin
2023-11-25 09:54:29,574 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:54:29,576 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:54:33,785 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:35,068 - INFO - Use pytorch device: cpu
2023-11-25 09:54:35,068 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:36,107 - INFO - Use pytorch device: cpu
2023-11-25 09:54:36,216 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:54:36,330 - DEBUG - Starting component System
2023-11-25 09:54:36,330 - DEBUG - Starting component Posthog
2023-11-25 09:54:36,330 - DEBUG - Starting component SqliteDB
2023-11-25 09:54:36,332 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:54:36,332 - DEBUG - Starting component SegmentAPI
2023-11-25 09:54:36,334 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:36,884 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 09:54:37,092 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:54:37,399 - INFO - Use pytorch device: cpu
2023-11-25 09:54:37,400 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:38,500 - INFO - Use pytorch device: cpu
2023-11-25 09:54:38,501 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:39,574 - INFO - Use pytorch device: cpu
2023-11-25 09:54:39,575 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:54:39,576 - DEBUG - Starting component System
2023-11-25 09:54:39,576 - DEBUG - Starting component Posthog
2023-11-25 09:54:39,576 - DEBUG - Starting component SqliteDB
2023-11-25 09:54:39,578 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:54:39,579 - DEBUG - Starting component SegmentAPI
2023-11-25 09:54:39,580 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:54:40,084 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:54:40,922 - INFO - Use pytorch device: cpu
2023-11-25 09:54:40,925 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:54:40,925 - DEBUG - Starting component System
2023-11-25 09:54:40,926 - DEBUG - Starting component Posthog
2023-11-25 09:54:40,926 - DEBUG - Starting component SqliteDB
2023-11-25 09:54:40,928 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:54:40,928 - DEBUG - Starting component SegmentAPI
2023-11-25 09:54:40,931 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:54:40,931 - DEBUG - Starting component System
2023-11-25 09:54:40,932 - DEBUG - Starting component Posthog
2023-11-25 09:54:40,932 - DEBUG - Starting component SqliteDB
2023-11-25 09:54:40,934 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:54:40,934 - DEBUG - Starting component SegmentAPI
2023-11-25 09:54:41,150 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:54:41,218 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:54:41,273 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:54:41,273 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:54:41,274 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 09:54:41,319 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 09:54:44,779 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:54:44,781 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3025 request_id=37f1f3996800d4ec61c73e5e613e35e7 response_code=200
2023-11-25 09:54:44,930 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:54:45,188 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:54:45,189 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:54:48,688 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:54:48,689 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3356 request_id=f228b9fa68605ade77db5f921d550a73 response_code=200
2023-11-25 09:56:42,914 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 09:56:42,921 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 09:56:42,922 - DEBUG - interactive is False
2023-11-25 09:56:42,922 - DEBUG - platform is darwin
2023-11-25 09:56:42,990 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 09:56:42,993 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 09:56:48,368 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:49,945 - INFO - Use pytorch device: cpu
2023-11-25 09:56:49,945 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:51,044 - INFO - Use pytorch device: cpu
2023-11-25 09:56:51,168 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:56:51,287 - DEBUG - Starting component System
2023-11-25 09:56:51,287 - DEBUG - Starting component Posthog
2023-11-25 09:56:51,287 - DEBUG - Starting component SqliteDB
2023-11-25 09:56:51,289 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:56:51,289 - DEBUG - Starting component SegmentAPI
2023-11-25 09:56:51,291 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:51,829 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 09:56:52,184 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:56:52,449 - INFO - Use pytorch device: cpu
2023-11-25 09:56:52,449 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:53,614 - INFO - Use pytorch device: cpu
2023-11-25 09:56:53,614 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:54,775 - INFO - Use pytorch device: cpu
2023-11-25 09:56:54,777 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:56:54,778 - DEBUG - Starting component System
2023-11-25 09:56:54,778 - DEBUG - Starting component Posthog
2023-11-25 09:56:54,778 - DEBUG - Starting component SqliteDB
2023-11-25 09:56:54,782 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:56:54,782 - DEBUG - Starting component SegmentAPI
2023-11-25 09:56:54,783 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 09:56:55,257 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:56:58,015 - INFO - Use pytorch device: cpu
2023-11-25 09:56:58,018 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:56:58,019 - DEBUG - Starting component System
2023-11-25 09:56:58,019 - DEBUG - Starting component Posthog
2023-11-25 09:56:58,019 - DEBUG - Starting component SqliteDB
2023-11-25 09:56:58,022 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:56:58,022 - DEBUG - Starting component SegmentAPI
2023-11-25 09:56:58,025 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 09:56:58,026 - DEBUG - Starting component System
2023-11-25 09:56:58,026 - DEBUG - Starting component Posthog
2023-11-25 09:56:58,026 - DEBUG - Starting component SqliteDB
2023-11-25 09:56:58,030 - DEBUG - Starting component LocalSegmentManager
2023-11-25 09:56:58,030 - DEBUG - Starting component SegmentAPI
2023-11-25 09:56:58,199 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 09:56:58,637 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:56:58,697 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:56:58,697 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 09:56:58,698 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 09:56:58,748 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 09:57:02,137 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 09:57:02,140 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2953 request_id=c8b5d9a4768062e0f8f4466c85fd04a0 response_code=200
2023-11-25 09:57:02,349 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 09:57:02,615 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 09:57:02,616 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:00:45,370 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:00:45,377 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:00:45,378 - DEBUG - interactive is False
2023-11-25 10:00:45,378 - DEBUG - platform is darwin
2023-11-25 10:00:45,439 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:00:45,442 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:00:49,786 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:51,447 - INFO - Use pytorch device: cpu
2023-11-25 10:00:51,447 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:52,482 - INFO - Use pytorch device: cpu
2023-11-25 10:00:52,588 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:00:52,703 - DEBUG - Starting component System
2023-11-25 10:00:52,704 - DEBUG - Starting component Posthog
2023-11-25 10:00:52,704 - DEBUG - Starting component SqliteDB
2023-11-25 10:00:52,709 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:00:52,709 - DEBUG - Starting component SegmentAPI
2023-11-25 10:00:52,712 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:53,256 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:00:53,589 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:00:53,773 - INFO - Use pytorch device: cpu
2023-11-25 10:00:53,774 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:54,940 - INFO - Use pytorch device: cpu
2023-11-25 10:00:54,940 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:56,198 - INFO - Use pytorch device: cpu
2023-11-25 10:00:56,200 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:00:56,200 - DEBUG - Starting component System
2023-11-25 10:00:56,201 - DEBUG - Starting component Posthog
2023-11-25 10:00:56,201 - DEBUG - Starting component SqliteDB
2023-11-25 10:00:56,206 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:00:56,206 - DEBUG - Starting component SegmentAPI
2023-11-25 10:00:56,209 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:00:56,668 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:00:58,793 - INFO - Use pytorch device: cpu
2023-11-25 10:00:58,795 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:00:58,796 - DEBUG - Starting component System
2023-11-25 10:00:58,796 - DEBUG - Starting component Posthog
2023-11-25 10:00:58,796 - DEBUG - Starting component SqliteDB
2023-11-25 10:00:58,798 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:00:58,798 - DEBUG - Starting component SegmentAPI
2023-11-25 10:00:58,800 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:00:58,801 - DEBUG - Starting component System
2023-11-25 10:00:58,801 - DEBUG - Starting component Posthog
2023-11-25 10:00:58,801 - DEBUG - Starting component SqliteDB
2023-11-25 10:00:58,804 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:00:58,804 - DEBUG - Starting component SegmentAPI
2023-11-25 10:00:59,266 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:00:59,297 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:00:59,353 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:00:59,354 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:00:59,354 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:00:59,405 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:01:03,356 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:01:03,358 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3450 request_id=321bd92c5c3743dc1934bd5f6fdfdf9f response_code=200
2023-11-25 10:01:03,501 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:01:03,767 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:01:03,767 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:01:05,453 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:01:05,453 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1542 request_id=518362339513b98941e08af2455faca6 response_code=200
2023-11-25 10:01:05,456 - INFO - 1.1956020418214854
2023-11-25 10:01:05,459 - INFO - 1.1956020418214854
2023-11-25 10:01:05,612 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:01:05,613 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:01:05,623 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:01:05,623 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,623 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,624 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:01:05,625 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,626 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,627 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,627 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,627 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:01:05,627 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:01:05,627 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,628 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,628 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,628 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,629 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,629 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,629 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,629 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,629 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,630 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:01:05,631 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,632 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:01:05,633 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,634 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:01:05,635 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,635 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,635 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:01:05,636 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,637 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,638 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,639 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,640 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:01:05,641 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:01:05,642 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,643 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,644 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,645 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,646 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,646 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,646 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,646 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,646 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,647 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:01:05,648 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,648 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,648 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,648 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,649 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,650 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,651 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,652 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,653 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,654 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,655 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,656 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:01:05,657 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,658 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:01:05,659 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,660 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:01:05,661 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,662 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:01:05,663 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,663 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,663 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,663 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,664 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,664 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,664 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,664 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,664 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,665 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,666 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,666 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:01:05,666 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,666 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,666 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:01:05,666 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:02:16,630 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:02:16,636 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:02:16,638 - DEBUG - interactive is False
2023-11-25 10:02:16,638 - DEBUG - platform is darwin
2023-11-25 10:02:16,703 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:02:16,705 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:02:21,811 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:23,552 - INFO - Use pytorch device: cpu
2023-11-25 10:02:23,552 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:24,803 - INFO - Use pytorch device: cpu
2023-11-25 10:02:24,912 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:02:25,008 - DEBUG - Starting component System
2023-11-25 10:02:25,008 - DEBUG - Starting component Posthog
2023-11-25 10:02:25,008 - DEBUG - Starting component SqliteDB
2023-11-25 10:02:25,013 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:02:25,013 - DEBUG - Starting component SegmentAPI
2023-11-25 10:02:25,015 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:25,555 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:02:25,895 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:02:26,134 - INFO - Use pytorch device: cpu
2023-11-25 10:02:26,135 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:27,248 - INFO - Use pytorch device: cpu
2023-11-25 10:02:27,249 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:28,355 - INFO - Use pytorch device: cpu
2023-11-25 10:02:28,357 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:02:28,358 - DEBUG - Starting component System
2023-11-25 10:02:28,359 - DEBUG - Starting component Posthog
2023-11-25 10:02:28,359 - DEBUG - Starting component SqliteDB
2023-11-25 10:02:28,361 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:02:28,362 - DEBUG - Starting component SegmentAPI
2023-11-25 10:02:28,363 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:02:28,484 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:02:31,318 - INFO - Use pytorch device: cpu
2023-11-25 10:02:31,330 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:02:31,333 - DEBUG - Starting component System
2023-11-25 10:02:31,334 - DEBUG - Starting component Posthog
2023-11-25 10:02:31,334 - DEBUG - Starting component SqliteDB
2023-11-25 10:02:31,342 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:02:31,342 - DEBUG - Starting component SegmentAPI
2023-11-25 10:02:31,351 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:02:31,352 - DEBUG - Starting component System
2023-11-25 10:02:31,352 - DEBUG - Starting component Posthog
2023-11-25 10:02:31,352 - DEBUG - Starting component SqliteDB
2023-11-25 10:02:31,357 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:02:31,358 - DEBUG - Starting component SegmentAPI
2023-11-25 10:02:31,650 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:02:32,152 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:02:32,214 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:02:32,215 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:02:32,215 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:02:32,277 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:02:34,796 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:02:34,798 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1966 request_id=25a787928805875021a07756988e0e23 response_code=200
2023-11-25 10:02:34,961 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:02:35,248 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:02:35,248 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:02:37,017 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:02:37,018 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1641 request_id=40f7a2b5a3a648e88a04cf1f22fee9cc response_code=200
2023-11-25 10:02:37,022 - INFO - 0.9258501499770689
2023-11-25 10:02:37,022 - INFO - 0.9258501499770689
2023-11-25 10:02:37,039 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:02:37,041 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:02:37,056 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,057 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,058 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,059 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,060 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:02:37,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:02:37,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:02:37,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:02:37,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,087 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,088 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,089 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,090 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:02:37,091 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:05:59,110 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:05:59,111 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:05:59,114 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:05:59,166 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:09:11,706 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:09:11,707 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:09:11,708 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:09:11,744 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:09:13,777 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:09:13,780 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1517 request_id=3a9cc8e0f3cf4f78ed3df37e83de533f response_code=200
2023-11-25 10:09:13,953 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:09:13,953 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:09:15,706 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:09:15,708 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1537 request_id=fdf3563cd1f1df65861512be34331a6c response_code=200
2023-11-25 10:09:15,712 - INFO - 0.9258501499770689
2023-11-25 10:09:15,713 - INFO - 0.9258501499770689
2023-11-25 10:16:07,692 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:16:07,698 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:16:07,700 - DEBUG - interactive is False
2023-11-25 10:16:07,700 - DEBUG - platform is darwin
2023-11-25 10:16:07,761 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:16:07,764 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:16:12,678 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:14,388 - INFO - Use pytorch device: cpu
2023-11-25 10:16:14,388 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:15,421 - INFO - Use pytorch device: cpu
2023-11-25 10:16:15,530 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:16:15,639 - DEBUG - Starting component System
2023-11-25 10:16:15,639 - DEBUG - Starting component Posthog
2023-11-25 10:16:15,639 - DEBUG - Starting component SqliteDB
2023-11-25 10:16:15,645 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:16:15,645 - DEBUG - Starting component SegmentAPI
2023-11-25 10:16:15,648 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:16,189 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:16:16,549 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:16:16,702 - INFO - Use pytorch device: cpu
2023-11-25 10:16:16,703 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:17,817 - INFO - Use pytorch device: cpu
2023-11-25 10:16:17,819 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:20,315 - INFO - Use pytorch device: cpu
2023-11-25 10:16:20,318 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:16:20,320 - DEBUG - Starting component System
2023-11-25 10:16:20,320 - DEBUG - Starting component Posthog
2023-11-25 10:16:20,321 - DEBUG - Starting component SqliteDB
2023-11-25 10:16:20,325 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:16:20,325 - DEBUG - Starting component SegmentAPI
2023-11-25 10:16:20,331 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:16:20,633 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:16:21,838 - INFO - Use pytorch device: cpu
2023-11-25 10:16:21,840 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:16:21,840 - DEBUG - Starting component System
2023-11-25 10:16:21,840 - DEBUG - Starting component Posthog
2023-11-25 10:16:21,841 - DEBUG - Starting component SqliteDB
2023-11-25 10:16:21,843 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:16:21,844 - DEBUG - Starting component SegmentAPI
2023-11-25 10:16:21,846 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:16:21,847 - DEBUG - Starting component System
2023-11-25 10:16:21,847 - DEBUG - Starting component Posthog
2023-11-25 10:16:21,847 - DEBUG - Starting component SqliteDB
2023-11-25 10:16:21,849 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:16:21,849 - DEBUG - Starting component SegmentAPI
2023-11-25 10:16:22,202 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:16:22,515 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:16:22,572 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:16:22,573 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:16:22,573 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:16:22,611 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:16:25,669 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:16:25,672 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2531 request_id=7971650926c98d930da67d514d246a4c response_code=200
2023-11-25 10:16:25,812 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:16:26,198 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:16:26,198 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:16:29,662 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:16:29,663 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3214 request_id=e7e409801501e4a269359b8d38243275 response_code=200
2023-11-25 10:16:29,667 - INFO - 0.5812202407571408
2023-11-25 10:16:29,668 - INFO - 0.5812202407571408
2023-11-25 10:16:29,689 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:16:29,691 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:16:29,702 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:16:29,702 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,702 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:16:29,702 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:16:29,703 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:16:29,704 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,705 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,706 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,707 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,708 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,709 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,710 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,711 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,712 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,713 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,714 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,715 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,716 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,717 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,718 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,719 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,720 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,721 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,722 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,723 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,724 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,725 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,726 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,727 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,728 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,729 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,730 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,731 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,732 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:16:29,733 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,734 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,735 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,736 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:16:29,737 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:19:49,130 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:19:56,669 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:00,478 - INFO - Use pytorch device: cpu
2023-11-25 10:20:00,481 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:03,060 - INFO - Use pytorch device: cpu
2023-11-25 10:20:03,074 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:20:03,078 - DEBUG - Starting component System
2023-11-25 10:20:03,078 - DEBUG - Starting component Posthog
2023-11-25 10:20:03,078 - DEBUG - Starting component SqliteDB
2023-11-25 10:20:03,089 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:20:03,090 - DEBUG - Starting component SegmentAPI
2023-11-25 10:20:03,096 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:03,300 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:20:04,382 - INFO - Use pytorch device: cpu
2023-11-25 10:20:04,384 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:06,898 - INFO - Use pytorch device: cpu
2023-11-25 10:20:06,899 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:09,323 - INFO - Use pytorch device: cpu
2023-11-25 10:20:09,330 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:20:09,331 - DEBUG - Starting component System
2023-11-25 10:20:09,332 - DEBUG - Starting component Posthog
2023-11-25 10:20:09,332 - DEBUG - Starting component SqliteDB
2023-11-25 10:20:09,341 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:20:09,341 - DEBUG - Starting component SegmentAPI
2023-11-25 10:20:09,345 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:20:09,893 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:20:11,764 - INFO - Use pytorch device: cpu
2023-11-25 10:20:11,770 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:20:11,771 - DEBUG - Starting component System
2023-11-25 10:20:11,772 - DEBUG - Starting component Posthog
2023-11-25 10:20:11,772 - DEBUG - Starting component SqliteDB
2023-11-25 10:20:11,776 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:20:11,777 - DEBUG - Starting component SegmentAPI
2023-11-25 10:20:11,781 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:20:11,781 - DEBUG - Starting component System
2023-11-25 10:20:11,781 - DEBUG - Starting component Posthog
2023-11-25 10:20:11,782 - DEBUG - Starting component SqliteDB
2023-11-25 10:20:11,784 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:20:11,784 - DEBUG - Starting component SegmentAPI
2023-11-25 10:20:11,974 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:20:12,424 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:20:12,497 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:20:12,497 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:20:12,511 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:20:12,555 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:20:14,075 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:20:14,077 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1007 request_id=4830c03ca9c1d1adb9ee79ccd1f2d94f response_code=200
2023-11-25 10:20:14,421 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:20:14,744 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:20:14,744 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:20:16,421 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:20:16,422 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1540 request_id=7f2a3de5ea4ccd342ae54c11988053bd response_code=200
2023-11-25 10:20:16,428 - INFO - 1.2534417531564797
2023-11-25 10:20:16,429 - INFO - 1.2534417531564797
2023-11-25 10:21:40,360 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:21:40,367 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:21:40,368 - DEBUG - interactive is False
2023-11-25 10:21:40,369 - DEBUG - platform is darwin
2023-11-25 10:21:40,432 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:21:40,434 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:21:45,977 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:47,746 - INFO - Use pytorch device: cpu
2023-11-25 10:21:47,747 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:48,995 - INFO - Use pytorch device: cpu
2023-11-25 10:21:49,133 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:21:49,260 - DEBUG - Starting component System
2023-11-25 10:21:49,260 - DEBUG - Starting component Posthog
2023-11-25 10:21:49,260 - DEBUG - Starting component SqliteDB
2023-11-25 10:21:49,269 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:21:49,269 - DEBUG - Starting component SegmentAPI
2023-11-25 10:21:49,274 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:49,818 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:21:50,216 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:21:50,680 - INFO - Use pytorch device: cpu
2023-11-25 10:21:50,681 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:51,910 - INFO - Use pytorch device: cpu
2023-11-25 10:21:51,925 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:53,208 - INFO - Use pytorch device: cpu
2023-11-25 10:21:53,211 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:21:53,212 - DEBUG - Starting component System
2023-11-25 10:21:53,212 - DEBUG - Starting component Posthog
2023-11-25 10:21:53,213 - DEBUG - Starting component SqliteDB
2023-11-25 10:21:53,217 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:21:53,217 - DEBUG - Starting component SegmentAPI
2023-11-25 10:21:53,220 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:21:53,307 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:21:54,714 - INFO - Use pytorch device: cpu
2023-11-25 10:21:54,717 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:21:54,719 - DEBUG - Starting component System
2023-11-25 10:21:54,719 - DEBUG - Starting component Posthog
2023-11-25 10:21:54,719 - DEBUG - Starting component SqliteDB
2023-11-25 10:21:54,725 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:21:54,725 - DEBUG - Starting component SegmentAPI
2023-11-25 10:21:54,728 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:21:54,729 - DEBUG - Starting component System
2023-11-25 10:21:54,729 - DEBUG - Starting component Posthog
2023-11-25 10:21:54,730 - DEBUG - Starting component SqliteDB
2023-11-25 10:21:54,732 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:21:54,732 - DEBUG - Starting component SegmentAPI
2023-11-25 10:21:55,015 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:21:55,134 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:21:55,194 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:21:55,195 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:21:55,195 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:21:55,237 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:22:02,555 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:22:02,557 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6820 request_id=aaa9d51ff33b47eb9661bc1d8aa5532b response_code=200
2023-11-25 10:22:02,688 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:22:02,943 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:22:02,943 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n to perform well in diverse contexts.\\n\\n to perform well in diverse contexts.\\n\\n well as their training time, number of\\nparameters, and amount of data they could process.\\n\\n well as their training time, number of\\nparameters, and amount of data they could process."}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:22:07,828 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:22:07,830 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4693 request_id=3874484685d3a26b1b4e1c74d53d0ddd response_code=200
2023-11-25 10:22:07,833 - INFO - 0.8640482571680719
2023-11-25 10:22:07,835 - INFO - 0.8640482571680719
2023-11-25 10:22:07,858 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:22:07,859 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:22:07,871 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:22:07,872 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,872 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:22:07,872 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,872 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:22:07,873 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,874 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,875 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,876 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,877 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,878 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:22:07,879 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,880 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:22:07,881 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,882 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,883 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,884 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,885 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:22:07,886 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:22:07,887 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:22:07,888 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,889 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,890 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,891 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,892 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,893 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,894 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,895 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,896 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,897 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,898 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,899 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,900 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,901 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,902 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,903 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,904 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,905 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,906 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,906 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:22:07,906 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,906 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,906 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:22:07,906 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:24:03,168 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:24:03,174 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:24:03,176 - DEBUG - interactive is False
2023-11-25 10:24:03,176 - DEBUG - platform is darwin
2023-11-25 10:24:03,244 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:24:03,247 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:24:07,698 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:09,160 - INFO - Use pytorch device: cpu
2023-11-25 10:24:09,161 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:10,258 - INFO - Use pytorch device: cpu
2023-11-25 10:24:10,379 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:24:10,493 - DEBUG - Starting component System
2023-11-25 10:24:10,493 - DEBUG - Starting component Posthog
2023-11-25 10:24:10,493 - DEBUG - Starting component SqliteDB
2023-11-25 10:24:10,497 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:24:10,498 - DEBUG - Starting component SegmentAPI
2023-11-25 10:24:10,501 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:11,035 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:24:11,260 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:24:11,623 - INFO - Use pytorch device: cpu
2023-11-25 10:24:11,624 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:12,732 - INFO - Use pytorch device: cpu
2023-11-25 10:24:12,733 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:13,858 - INFO - Use pytorch device: cpu
2023-11-25 10:24:13,861 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:24:13,862 - DEBUG - Starting component System
2023-11-25 10:24:13,862 - DEBUG - Starting component Posthog
2023-11-25 10:24:13,862 - DEBUG - Starting component SqliteDB
2023-11-25 10:24:13,865 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:24:13,865 - DEBUG - Starting component SegmentAPI
2023-11-25 10:24:13,866 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:24:14,350 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:24:15,531 - INFO - Use pytorch device: cpu
2023-11-25 10:24:15,533 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:24:15,534 - DEBUG - Starting component System
2023-11-25 10:24:15,534 - DEBUG - Starting component Posthog
2023-11-25 10:24:15,534 - DEBUG - Starting component SqliteDB
2023-11-25 10:24:15,536 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:24:15,536 - DEBUG - Starting component SegmentAPI
2023-11-25 10:24:15,538 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:24:15,539 - DEBUG - Starting component System
2023-11-25 10:24:15,539 - DEBUG - Starting component Posthog
2023-11-25 10:24:15,539 - DEBUG - Starting component SqliteDB
2023-11-25 10:24:15,542 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:24:15,542 - DEBUG - Starting component SegmentAPI
2023-11-25 10:24:15,914 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:24:16,053 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:24:16,111 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:24:16,111 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:24:16,112 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:24:16,136 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:24:18,840 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:24:18,843 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2216 request_id=a62b9ccb60a3671c7c549eaafcda6258 response_code=200
2023-11-25 10:24:18,978 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:24:19,240 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:24:19,240 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:24:22,015 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:24:22,016 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2588 request_id=7431b7ee2fef2ee79d2085ade0b2388b response_code=200
2023-11-25 10:24:22,019 - INFO - 0.7287264092271902
2023-11-25 10:24:22,021 - INFO - 0.7287264092271902
2023-11-25 10:24:22,043 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:24:22,045 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:24:22,051 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,052 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,053 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,054 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,055 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,056 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,057 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,058 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:24:22,058 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:24:22,058 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,058 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,058 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,059 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,060 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,061 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,062 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,063 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,064 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,065 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,066 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:24:22,067 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:24:22,068 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,069 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,070 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:24:22,071 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,072 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,073 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,074 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,075 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,076 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,077 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,078 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,079 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,080 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:24:22,081 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:24:22,082 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,083 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,084 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,085 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:24:22,086 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:29:25,417 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:29:25,424 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:29:25,425 - DEBUG - interactive is False
2023-11-25 10:29:25,426 - DEBUG - platform is darwin
2023-11-25 10:29:25,487 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:29:25,490 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:29:30,456 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:32,073 - INFO - Use pytorch device: cpu
2023-11-25 10:29:32,074 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:33,228 - INFO - Use pytorch device: cpu
2023-11-25 10:29:33,356 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:29:33,473 - DEBUG - Starting component System
2023-11-25 10:29:33,474 - DEBUG - Starting component Posthog
2023-11-25 10:29:33,474 - DEBUG - Starting component SqliteDB
2023-11-25 10:29:33,480 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:29:33,480 - DEBUG - Starting component SegmentAPI
2023-11-25 10:29:33,484 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:34,057 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:29:34,312 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:29:34,698 - INFO - Use pytorch device: cpu
2023-11-25 10:29:34,700 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:36,011 - INFO - Use pytorch device: cpu
2023-11-25 10:29:36,011 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:38,933 - INFO - Use pytorch device: cpu
2023-11-25 10:29:38,948 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:29:38,952 - DEBUG - Starting component System
2023-11-25 10:29:38,953 - DEBUG - Starting component Posthog
2023-11-25 10:29:38,953 - DEBUG - Starting component SqliteDB
2023-11-25 10:29:38,960 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:29:38,960 - DEBUG - Starting component SegmentAPI
2023-11-25 10:29:38,969 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:29:39,468 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:29:41,935 - INFO - Use pytorch device: cpu
2023-11-25 10:29:41,938 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:29:41,939 - DEBUG - Starting component System
2023-11-25 10:29:41,939 - DEBUG - Starting component Posthog
2023-11-25 10:29:41,939 - DEBUG - Starting component SqliteDB
2023-11-25 10:29:41,942 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:29:41,942 - DEBUG - Starting component SegmentAPI
2023-11-25 10:29:41,944 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:29:41,945 - DEBUG - Starting component System
2023-11-25 10:29:41,945 - DEBUG - Starting component Posthog
2023-11-25 10:29:41,945 - DEBUG - Starting component SqliteDB
2023-11-25 10:29:41,947 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:29:41,947 - DEBUG - Starting component SegmentAPI
2023-11-25 10:29:42,272 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:29:42,846 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:29:42,919 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:29:42,920 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:29:42,920 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:29:42,970 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:29:46,714 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:29:46,717 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3167 request_id=07bb584ca86bab7606d3e309dd560569 response_code=200
2023-11-25 10:29:46,865 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:29:47,178 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:29:47,178 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:29:48,353 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:29:48,355 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=920 request_id=516e4ff76eb9157755fb638a6e98b399 response_code=200
2023-11-25 10:29:48,359 - INFO - 0.809693008695661
2023-11-25 10:29:48,360 - INFO - 0.809693008695661
2023-11-25 10:29:48,385 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:29:48,386 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:29:48,396 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,397 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,398 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,399 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:29:48,400 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,401 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,402 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,403 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,404 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,405 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,405 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,405 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,405 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,406 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,407 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,408 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,409 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,410 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:29:48,411 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,412 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:29:48,413 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,414 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,415 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:29:48,416 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,417 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,418 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,419 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,420 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,421 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,422 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,423 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,424 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,425 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:29:48,426 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,427 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,428 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,429 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:29:48,430 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,431 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,432 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:29:48,432 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:31:18,775 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:31:18,781 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:31:18,782 - DEBUG - interactive is False
2023-11-25 10:31:18,782 - DEBUG - platform is darwin
2023-11-25 10:31:18,852 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:31:18,855 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:31:23,181 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:24,452 - INFO - Use pytorch device: cpu
2023-11-25 10:31:24,452 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:25,544 - INFO - Use pytorch device: cpu
2023-11-25 10:31:25,650 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:31:25,765 - DEBUG - Starting component System
2023-11-25 10:31:25,766 - DEBUG - Starting component Posthog
2023-11-25 10:31:25,766 - DEBUG - Starting component SqliteDB
2023-11-25 10:31:25,768 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:31:25,768 - DEBUG - Starting component SegmentAPI
2023-11-25 10:31:25,770 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:26,337 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:31:26,832 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:31:26,833 - INFO - Use pytorch device: cpu
2023-11-25 10:31:26,834 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:27,935 - INFO - Use pytorch device: cpu
2023-11-25 10:31:27,935 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:29,059 - INFO - Use pytorch device: cpu
2023-11-25 10:31:29,061 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:31:29,061 - DEBUG - Starting component System
2023-11-25 10:31:29,062 - DEBUG - Starting component Posthog
2023-11-25 10:31:29,062 - DEBUG - Starting component SqliteDB
2023-11-25 10:31:29,064 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:31:29,064 - DEBUG - Starting component SegmentAPI
2023-11-25 10:31:29,065 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:31:29,404 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:31:30,465 - INFO - Use pytorch device: cpu
2023-11-25 10:31:30,467 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:31:30,467 - DEBUG - Starting component System
2023-11-25 10:31:30,468 - DEBUG - Starting component Posthog
2023-11-25 10:31:30,468 - DEBUG - Starting component SqliteDB
2023-11-25 10:31:30,470 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:31:30,470 - DEBUG - Starting component SegmentAPI
2023-11-25 10:31:30,473 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:31:30,473 - DEBUG - Starting component System
2023-11-25 10:31:30,474 - DEBUG - Starting component Posthog
2023-11-25 10:31:30,474 - DEBUG - Starting component SqliteDB
2023-11-25 10:31:30,476 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:31:30,476 - DEBUG - Starting component SegmentAPI
2023-11-25 10:31:30,730 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:31:30,787 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:31:30,787 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:31:30,788 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:31:30,829 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:31:30,955 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:31:32,489 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:31:32,491 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1121 request_id=3eb4f7cedfdd5666d9a6593e039d82d0 response_code=200
2023-11-25 10:31:32,756 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:31:33,066 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:31:33,066 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:31:35,052 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:31:35,052 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1835 request_id=0a2aebf53c86836c2c3a08ad9e21c714 response_code=200
2023-11-25 10:31:35,055 - INFO - 0.6914352078114849
2023-11-25 10:31:35,056 - INFO - 0.6914352078114849
2023-11-25 10:31:35,073 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:31:35,074 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:31:35,082 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:31:35,083 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,084 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:31:35,085 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,085 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,085 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,086 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,086 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,087 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,087 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,087 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,087 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,087 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,088 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:31:35,088 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,088 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,088 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,089 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,089 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,089 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,089 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,089 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,090 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,091 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,092 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,093 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,094 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:31:35,095 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,096 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,097 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,098 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,099 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,100 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,101 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,102 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,103 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:31:35,104 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,105 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,106 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,107 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,108 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,109 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,110 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,111 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,112 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,113 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,114 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,115 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,116 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,117 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,118 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,119 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,120 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,121 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:31:35,122 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,123 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,124 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:31:35,125 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:32:12,421 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:32:12,427 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:32:12,429 - DEBUG - interactive is False
2023-11-25 10:32:12,429 - DEBUG - platform is darwin
2023-11-25 10:32:12,493 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:32:12,496 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:32:16,883 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:18,308 - INFO - Use pytorch device: cpu
2023-11-25 10:32:18,309 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:19,440 - INFO - Use pytorch device: cpu
2023-11-25 10:32:19,556 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:19,672 - DEBUG - Starting component System
2023-11-25 10:32:19,673 - DEBUG - Starting component Posthog
2023-11-25 10:32:19,673 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:19,676 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:19,676 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:19,678 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:20,188 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:32:20,551 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:20,801 - INFO - Use pytorch device: cpu
2023-11-25 10:32:20,802 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:21,939 - INFO - Use pytorch device: cpu
2023-11-25 10:32:21,939 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:23,102 - INFO - Use pytorch device: cpu
2023-11-25 10:32:23,105 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:23,106 - DEBUG - Starting component System
2023-11-25 10:32:23,106 - DEBUG - Starting component Posthog
2023-11-25 10:32:23,106 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:23,109 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:23,109 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:23,111 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:23,640 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:26,253 - INFO - Use pytorch device: cpu
2023-11-25 10:32:26,254 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:27,469 - INFO - Use pytorch device: cpu
2023-11-25 10:32:27,470 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:30,147 - INFO - Use pytorch device: cpu
2023-11-25 10:32:30,150 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:30,152 - DEBUG - Starting component System
2023-11-25 10:32:30,152 - DEBUG - Starting component Posthog
2023-11-25 10:32:30,152 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:30,157 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:30,157 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:30,162 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:30,393 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:31,377 - INFO - Use pytorch device: cpu
2023-11-25 10:32:31,377 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:35,272 - INFO - Use pytorch device: cpu
2023-11-25 10:32:35,275 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:38,152 - INFO - Use pytorch device: cpu
2023-11-25 10:32:38,166 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:38,171 - DEBUG - Starting component System
2023-11-25 10:32:38,172 - DEBUG - Starting component Posthog
2023-11-25 10:32:38,172 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:38,179 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:38,179 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:38,189 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:38,512 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:40,841 - INFO - Use pytorch device: cpu
2023-11-25 10:32:40,843 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:42,894 - INFO - Use pytorch device: cpu
2023-11-25 10:32:42,894 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:45,448 - INFO - Use pytorch device: cpu
2023-11-25 10:32:45,454 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:45,455 - DEBUG - Starting component System
2023-11-25 10:32:45,455 - DEBUG - Starting component Posthog
2023-11-25 10:32:45,455 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:45,461 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:45,461 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:45,463 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:32:45,642 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:48,744 - INFO - Use pytorch device: cpu
2023-11-25 10:32:48,763 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:48,771 - DEBUG - Starting component System
2023-11-25 10:32:48,772 - DEBUG - Starting component Posthog
2023-11-25 10:32:48,772 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:48,785 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:48,785 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:48,805 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:48,807 - DEBUG - Starting component System
2023-11-25 10:32:48,807 - DEBUG - Starting component Posthog
2023-11-25 10:32:48,808 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:48,816 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:48,816 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:48,827 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:48,828 - DEBUG - Starting component System
2023-11-25 10:32:48,829 - DEBUG - Starting component Posthog
2023-11-25 10:32:48,829 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:48,837 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:48,837 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:48,843 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:48,844 - DEBUG - Starting component System
2023-11-25 10:32:48,845 - DEBUG - Starting component Posthog
2023-11-25 10:32:48,845 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:48,851 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:48,851 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:48,859 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:32:48,860 - DEBUG - Starting component System
2023-11-25 10:32:48,861 - DEBUG - Starting component Posthog
2023-11-25 10:32:48,861 - DEBUG - Starting component SqliteDB
2023-11-25 10:32:48,866 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:32:48,866 - DEBUG - Starting component SegmentAPI
2023-11-25 10:32:49,283 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:32:50,566 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:32:50,652 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:32:50,652 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:32:50,653 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:32:50,705 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:32:55,532 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:32:55,542 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4017 request_id=2fbc46c2f61229ff8afb5d5ac8aa3a99 response_code=200
2023-11-25 10:32:56,106 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:32:56,441 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:32:56,441 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:32:57,615 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:32:57,616 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1021 request_id=488c3f0008c65585a120a94eef2db42a response_code=200
2023-11-25 10:32:58,195 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:32:58,236 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:32:58,237 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 10:33:01,369 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:33:01,370 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2888 request_id=d651a5c4f027c28aed7d374c175a10c8 response_code=200
2023-11-25 10:33:01,797 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:33:02,057 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:33:02,058 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:33:05,671 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:33:05,673 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3302 request_id=2d543243c5529efa9337f64ad50e1bd2 response_code=200
2023-11-25 10:33:05,783 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:33:05,827 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:33:05,827 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 10:33:07,931 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:33:07,933 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1871 request_id=a0338c8ae14d911591bdd0611167d627 response_code=200
2023-11-25 10:33:07,940 - INFO - 1.2563395009434248
2023-11-25 10:33:07,944 - INFO - 1.2563395009434248
2023-11-25 10:33:07,945 - INFO - 1.2563395009434248
2023-11-25 10:33:07,945 - INFO - 1.2563395009434248
2023-11-25 10:33:07,945 - INFO - 1.2563395009434248
2023-11-25 10:33:07,972 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:33:07,975 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:33:08,007 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:33:08,009 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,009 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:33:08,009 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,010 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:33:08,011 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,012 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:33:08,013 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,014 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,014 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,015 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,015 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,015 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,015 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,015 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,016 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,016 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:33:08,016 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,016 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,016 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:33:08,017 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,018 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,019 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,020 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,021 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,022 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,023 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,024 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,025 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,026 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,027 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,028 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,029 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,030 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,031 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,032 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,033 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:33:08,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,034 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,035 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,036 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,037 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,038 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,039 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,040 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,041 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,042 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,043 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,044 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,045 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,046 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,047 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,048 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,049 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,050 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:33:08,051 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-11-25 10:48:59,981 - DEBUG - matplotlib data path: /Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data
2023-11-25 10:48:59,992 - DEBUG - CONFIGDIR=/Users/kjams/.matplotlib
2023-11-25 10:48:59,994 - DEBUG - interactive is False
2023-11-25 10:48:59,995 - DEBUG - platform is darwin
2023-11-25 10:49:00,075 - DEBUG - CACHEDIR=/Users/kjams/.matplotlib
2023-11-25 10:49:00,078 - DEBUG - Using fontManager instance from /Users/kjams/.matplotlib/fontlist-v330.json
2023-11-25 10:49:06,867 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:08,674 - INFO - Use pytorch device: cpu
2023-11-25 10:49:08,675 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:09,794 - INFO - Use pytorch device: cpu
2023-11-25 10:49:09,957 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:10,069 - DEBUG - Starting component System
2023-11-25 10:49:10,069 - DEBUG - Starting component Posthog
2023-11-25 10:49:10,069 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:10,077 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:10,078 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:10,083 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:10,656 - DEBUG - Starting new HTTPS connection (1): app.posthog.com:443
2023-11-25 10:49:11,025 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:11,221 - INFO - Use pytorch device: cpu
2023-11-25 10:49:11,223 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:12,459 - INFO - Use pytorch device: cpu
2023-11-25 10:49:12,464 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:15,317 - INFO - Use pytorch device: cpu
2023-11-25 10:49:15,325 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:15,328 - DEBUG - Starting component System
2023-11-25 10:49:15,329 - DEBUG - Starting component Posthog
2023-11-25 10:49:15,329 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:15,335 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:15,335 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:15,341 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:15,639 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:17,396 - INFO - Use pytorch device: cpu
2023-11-25 10:49:17,397 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:18,748 - INFO - Use pytorch device: cpu
2023-11-25 10:49:18,749 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:21,525 - INFO - Use pytorch device: cpu
2023-11-25 10:49:21,527 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:21,528 - DEBUG - Starting component System
2023-11-25 10:49:21,528 - DEBUG - Starting component Posthog
2023-11-25 10:49:21,528 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:21,533 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:21,533 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:21,536 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:21,627 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:22,925 - INFO - Use pytorch device: cpu
2023-11-25 10:49:22,925 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:24,388 - INFO - Use pytorch device: cpu
2023-11-25 10:49:24,388 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:27,162 - INFO - Use pytorch device: cpu
2023-11-25 10:49:27,176 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:27,182 - DEBUG - Starting component System
2023-11-25 10:49:27,183 - DEBUG - Starting component Posthog
2023-11-25 10:49:27,183 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:27,199 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:27,199 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:27,209 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:27,732 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:28,592 - INFO - Use pytorch device: cpu
2023-11-25 10:49:28,593 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:31,604 - INFO - Use pytorch device: cpu
2023-11-25 10:49:31,604 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:33,453 - INFO - Use pytorch device: cpu
2023-11-25 10:49:33,461 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:33,463 - DEBUG - Starting component System
2023-11-25 10:49:33,464 - DEBUG - Starting component Posthog
2023-11-25 10:49:33,464 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:33,470 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:33,470 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:33,474 - INFO - Load pretrained SentenceTransformer: facebook-dpr-ctx_encoder-multiset-base
2023-11-25 10:49:33,846 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:37,469 - INFO - Use pytorch device: cpu
2023-11-25 10:49:37,487 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:37,493 - DEBUG - Starting component System
2023-11-25 10:49:37,493 - DEBUG - Starting component Posthog
2023-11-25 10:49:37,493 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:37,503 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:37,503 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:37,520 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:37,521 - DEBUG - Starting component System
2023-11-25 10:49:37,522 - DEBUG - Starting component Posthog
2023-11-25 10:49:37,522 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:37,527 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:37,528 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:37,532 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:37,532 - DEBUG - Starting component System
2023-11-25 10:49:37,533 - DEBUG - Starting component Posthog
2023-11-25 10:49:37,533 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:37,538 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:37,538 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:37,542 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:37,545 - DEBUG - Starting component System
2023-11-25 10:49:37,545 - DEBUG - Starting component Posthog
2023-11-25 10:49:37,546 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:37,550 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:37,551 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:37,554 - INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.
2023-11-25 10:49:37,555 - DEBUG - Starting component System
2023-11-25 10:49:37,555 - DEBUG - Starting component Posthog
2023-11-25 10:49:37,555 - DEBUG - Starting component SqliteDB
2023-11-25 10:49:37,558 - DEBUG - Starting component LocalSegmentManager
2023-11-25 10:49:37,558 - DEBUG - Starting component SegmentAPI
2023-11-25 10:49:37,945 - DEBUG - https://app.posthog.com:443 "POST /batch/ HTTP/1.1" 200 None
2023-11-25 10:49:39,919 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:49:40,035 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:49:40,036 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker\\n\\nLearning to Act through Evolution of Neural Diversity in Random Neural Networks GECCO \\u201923, July 15\\u201319, 2023, Lisbon, Portugal\\n3EVOLVING DIVERSE NEURONS IN RANDOM\\nNEURAL NETWORKS\\nTypically, optimization of ANNs has been framed as the learning of\\ndistributed representations [ 5] that can become progressively more\\nabstract with the depth of the network. Optimization of weights, is a\\nprocess of fine-tuning the iterative transformation of one represen-\\ntation into another to end up with a new, more useful representation\\nof the input. How the intermediate layers respond to a given in-\\nput depends on the specific configuration of the weight matrix\\nresponsible for transforming the input as well as their activation\\nfunction.\\nRandomly-initialized networks can already perform useful com-\\nputations [ 28,30,61]. When neural units are trained specifically to\\ninterpret signals from a fixed random matrix, as is the case in this\\npaper, the initially arbitrary transformations will become mean-\\ningful to the function, as long as there exist detectable patterns\\nbetween the input the function receives and the output that the\\nfunction passes on and is evaluated on. Whether a pattern is de-\\ntectable depends on the expressiveness of the function. With this\\nin mind, it is reasonable to assume that if neurons in the network\\nare made more expressive, they can result in useful representations\\neven when provided with arbitrary transformations of the input.\\nMotivated by the diversity of neuron types in animal brains\\n[53], we aim to test how well a neural network-based agent can\\nperform reinforcement learning tasks through optimization of its\\nneuro-centric parameters alone without optimizing any of its neural\\nnetwork weights. An illustration of the neural model we optimize\\nin this paper is shown in Fig. 1. Each neural unit consists of a\\nsmall three-by-two matrix of values to be optimized. Each neural\\nunit in a layer is at each time step presented with a vector with\\nthree elements. The input value, propagated through the random\\nconnection from the previous layer, is concatenated with the current\\nstate of the neuron and a bias term. Together, these form a vector.\\nThe output of a neuron is the vector-matrix multiplication. From\\nthe perspective of a single neuron, this can be written as:\\n[\\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56]=\\ud835\\udc61\\ud835\\udc4e\\ud835\\udc5b\\u210e(n\\ud835\\udc59,\\ud835\\udc56\\u00b7[\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56,\\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56,1]\\ud835\\udc47). (1)\\nHere,\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the input value, \\u210e\\ud835\\udc61\\u22121\\n\\ud835\\udc59,\\ud835\\udc56is the state of the neuron, and\\nnl,ithe matrix of neural parameters, with \\ud835\\udc59denoting the current\\nlayer in the network, \\ud835\\udc56the placement of the neuron in the layer, and\\n\\ud835\\udc61is the current time step. The hyperbolic tangent function is used\\nfor non-linearity and to restrict output values to be in [-1, 1]. \\u02c6\\ud835\\udc65\\ud835\\udc61\\n\\ud835\\udc59+1,\\ud835\\udc57\\nis the value that is propagated through weights connecting to the\\nsubsequent layer, and \\u210e\\ud835\\udc61\\n\\ud835\\udc59,\\ud835\\udc56is the updated state of the neuron. As the\\nthree-by-two matrix has six values in total, we need to optimize six\\nparameters for each neuron in the network.\\nRepresenting a neuron by a small matrix means that the neuron\\ncan take more than a single value as input, as well as output more\\nthan one value. Here, we utilize this to endow each neuron with a\\nstate. The state of the neuron is integrated with the input through\\nthe optimized neural parameters. Part of the neuron\\u2019s output be-\\ncomes the new state of the neuron, which is fed back to the neuron\\nwith the next input. This turns our neurons into small dynamical\\nsystems. Presented with the same input value at different points\\nin the neuron\\u2019s history can thus yield different outputs. We find\\nthat stateful neurons provide a convenient and parameter-efficientway of equipping a network with some memory capabilities. One\\ncan see a layer of such neurons as a set of tiny recurrent neural net-\\nworks (RNNs) that are updated in parallel with local inputs, unique\\nto each RNN. As such, a layer of this proposed neural unit differs\\nfrom simple RNN architectures, such as Jordan Networks [ 34] or\\nElman Networks [ 15] in that a state associated with a neuron only\\naffects the next state and output of that particular neuron. These\\nlocal recurrent states only rely on the small matrix of the neural\\nunit, i.e.,\\ud835\\udc5btimes six parameters, where \\ud835\\udc5bis the number of neurons\\nin the layer. A recurrent layer of, e.g, an Elman Network requires an\\n\\ud835\\udc5b-by-\\ud835\\udc5bsized matrix to feed its activations back into itself. Addition-\\nally, the calculation of the neural state and the output of the neuron\\nare separated to a higher degree for the neural units, compared to\\nthe hidden state being a copy of the neural output.\\n4 EXPERIMENTS\\nWe optimize neural units in otherwise standard fully-connected\\nfeedforward neural networks. All networks in our experiments have\\ntwo hidden layers, containing 128and64neurons, respectively. We\\nuse learned neural units for all neurons, including in the input and\\noutput layers. The sizes of the input and output layers vary with\\nthe environments described below. The fixed weight values are\\nsampled fromN(0,0.5). We ran each experiment three times on\\ndifferent seeds, except for the weight-optimized models in the Car\\nRacing environment, which we ran only twice due to its longer\\ntraining times.\\nWhile neurons with recurrent states are common in the field of\\nspiking neural networks that emphasizes biological realism [ 21,22,\\n31,33], it is a departure from the simple neurons found in most\\nANNs. As a control, we also optimize neuro-centric parameters for\\nneurons without a recurrent state ( Simple Neuron ). The setup\\nfor optimizing these is very similar to that of the stateful neurons,\\nbut no part of the output of the vector-matrix multiplication is fed\\nback to the neuron\\u2019s input at the next time step. Instead of being\\nrepresented by three-by-two matrices, these simple neurons are\\nrepresented by two-by-one matrices (vectors in this case) and thus\\nhave fewer parameters to optimize. As such, the parameters of these\\nsimple neurons are simply a scalar of the neural input and a bias.\\nAs baselines, we optimize weights of standard feedforward net-\\nworks. For these, we run two different settings: one has a similar\\nnumber of adjustable parameters as the number of parameters in\\nthe neural unit approach ( Small FFNN ). To get the number of\\nweights to be similar to neural parameters, the widths and depths\\nof these networks have to be considerably smaller than the random\\nnetworks used in the main experiments. In the second baseline\\nsetting ( Same FFNN ), we train weights of networks that have the\\nsame widths and depths as the networks in the main experiments,\\nand thus many more adjustable parameters. Unless stated other-\\nwise, the activation function for all baseline experiments is the\\nhyperbolic tangent function for all neurons.\\n4.1 Environments\\nWe test the effectiveness of evolving a diverse set of neurons in\\nrandomly initialized networks in three diverse continuous control\\ntasks: the CartPoleSwingUp environment [ 20], the Bipedal Walker"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:49:40,037 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2023-11-25 10:49:40,101 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2023-11-25 10:49:45,351 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:49:45,358 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=4723 request_id=a460c48b936799cb48e8d9c72dda7c0e response_code=200
2023-11-25 10:49:46,095 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:49:46,520 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:49:46,520 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n, how can we responsibly anticipate and address the ethical\\nand societal considerations they raise? A recurring theme is that it is easier to reason about the\\nsocial impact of specific systems deployed to specific users than it is to reason about the social\\nimpact of foundation models, which could be adapted to any number of unforeseen downstream\\nsystems.\\nBefore attempting to answer these questions, we need to lay some groundwork. First, let us\\ndistinguish between research on foundation models and deployment of foundation models. Most of\\nwhat is publicly known is foundation models research \\u2014 through academic papers, demonstrations,\\nand progress on leaderboards. While the production of knowledge can play a vital role in shaping\\nthe future, the direct social impact is through the actual deployment of these models, which is\\ngoverned by proprietary practices on often private data. Sometimes the deployment is through\\nnew products \\u2014 e.g., GitHub\\u2019s Copilot6based on OpenAI\\u2019s Codex model [Chen\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and\\n\\n the success of neural networks over the last decade in modeling natural\\ndata is owed to the networks\\u2019 high depths , as could be roughly measured by the number of stacked\\nnon-linear layers they are composed of, or the number of computational steps they take during\\ntheir chain-of-reasoning. Great depths play a crucial role in enhancing networks\\u2019 expressivity,\\nallowing them to form powerful hierarchical anddistributed representations that could generalize\\nfrom the training data to new unseen examples [He et al. 2016b; Levine et al. 2020].\\nTheuniversal approximation theorem [Lu et al .2019b] indeed states that even simple multilayer\\nperceptrons (MLPs) can represent a broad set of functions, while different inductive biases , as those\\nimplemented in Recurrent Neural Networks (RNNs) or Convolutional Neural Networks (CNNs)\\n[Goodfellow et al .2016], can improve the learning efficiency and"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:49:53,328 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:49:53,330 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6617 request_id=5626c17df9973b994cebd06e95c165df response_code=200
2023-11-25 10:49:53,904 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:49:53,933 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:49:53,934 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications\\n\\nOn the Opportunities and Risks of Foundation Models 45\\ncompounded by the fact that AI responses can be unpredictable, and models can produce a vast\\ngenerative output space, making it difficult for people to build effective mental models of their\\nperformance. There has already been some progress on tackling these challenges in the form of\\nwork on interactive machine learning (e.g., Crayon [Fails and Olsen 2003], Regroup [Amershi et al .\\n2012]) and design frameworks for conveying uncertainty in AI to end-users (e.g., principles of mixed-\\ninitiative [Horvitz 1999]). However, more work is still needed to overcome these obstacles [Yang\\net al. 2020].\\nFoundation models pose important opportunities to address many of the challenges mentioned\\nabove. For instance, language-based foundation models\\u2019 ability to take natural language as input, and\\nto generalize to many downstream tasks, could significantly lower the difficulty \\u201cthreshold\\u201d [Myers\\net al.2000] for application development, i.e., by enabling the development of sophisticated models\\nwithout having to collect significant amounts of data and train large models from scratch. This\\ncould enable even non-ML experts to quickly prototype AI-infused applications. At the same time,\\nthe powerful generative and potentially multi-modal capabilities of foundation models could offer\\na far higher \\u201cceiling\\u201d [Myers et al .2000] of what types of interactions are achievable both in terms\\nof their quality and diversity as we will discuss below. However, how successfully we can leverage\\nthese capacities will depend on how effectively we can wrangle foundation models into forms that\\nwill be more manageable by application developers.\\nUnfortunately, the same generalizability and high ceiling that give foundation models their edge\\ncan also make these models difficult to work with, as they may be even more unpredictable and\\ncomplex than single-purpose AI models. Indeed, recent work has shown that it can be difficult to\\nmake models like GPT-3 consistently perform the intended task [Reynolds and McDonell 2021],\\nwhile understanding what it is capable of is still an active area of research [Hendrycks et al .\\n2021a]. In an effort to improve the reliability and trustworthiness of AI-infused applications, we\\nrecommend that future work should continue to investigate how to achieve more predictable\\nand robust behaviors from foundation models (e.g., through fine-tuning, or in cases where the\\nmain mode of interaction is natural language prompt, through prompt-engineering [Reynolds and\\nMcDonell 2021; Liu et al .2021d], calibrating [Zhao et al .2021], or pre-formatting a task-specific\\nendpoint.18Please see \\u00a74.8: robustness for more details).\\n2.5.2 Impact on end-user interaction with AI-infused applications.\\nBeyond the new ways developers might create AI-infused applications, what changes will foun-\\ndation models bring to the experience for end-users interacting with these applications? Existing\\ndesign frameworks for developing user-facing AI applications focus on augmenting (rather than\\nreplacing) users\\u2019 abilities as described by Douglas Engelbart [Engelbart 1963] \\u2014 we expect that\\nthese frameworks should and will remain relevant for the development of future AI-infused appli-\\ncations. For instance, maintaining users\\u2019 agency and reflecting their values will continue to be a\\ncentral theme for foundation model-powered applications. Additionally, the benefits of allowing\\nAI agents to take initiatives and automate users\\u2019 routines versus the benefits of waiting for users\\u2019\\ndirect manipulation [Shneiderman and Maes 1997] will need to be carefully weighed [Horvitz\\n1999]. Moreover, users\\u2019 values should be directly gathered and reflected through processes such\\nas participatory [Lee et al .2019] and value-sensitive design [Smith et al .2020] that advocate for\\nactively involving all stakeholders during the designing of the AI-infused applications.\\nThese issues may become especially salient with foundation models because the model may\\nbehave in ways that surprise and disappoint users and communities. Generative capabilities might\\nexpose biases or points of view that are counter to the communities\\u2019 goals, or more insidiously,\\n18https://beta.openai.com/docs/guides/classifications"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 10:49:57,426 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:49:57,427 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2435 request_id=a2d8e2e922c41dd71307da5e49ca7288 response_code=200
2023-11-25 10:49:57,815 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:49:58,053 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:49:58,053 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: \\n\\n3. COGNITIVE ENGINEERING 55 \\nUser -Centered Interface, which means providing intelligent, under - \\nstandable, tools that bridge the gap between people and systems: con- \\nvivial tools. \\nWhat Is It We Want in Computer Design? \\nApproximate science. In part we need a combined science and \\nengineering discipline that guides the design, construction, and use of \\nsystems. An important point to realize is that approximate methods suf- \\nJice, at least for most applications. This is true of most applied discip - \\nlines, from the linear model of transistor circuits to the stress analysis \\nof bridges and buildings: The engineering models are only approxima - \\ntions to reality, but the answers are precise enough for the purpose. \\nNote, of course, that the designer must know both the approximate \\nmodel and its limits. \\nConsider an example from Psychology: the nature of short -term \\nmemory (STM). Even though there is still not an agreed upon theory \\nof memory, and even though the exact nature of STM is still in doubt, \\nquite a bit is known about the phenomena of STM. The following \\napproximation captures a large portion of the phenomena of STM and \\nis, therefore, a valuable tool for many purposes: \\nThe five -slot approximate model of STM. Short -term \\nmemory consists of 5 slots, each capable of holding one item \\n(which might be a pointer to a complex memory structure). \\nEach item decays with a \\nhal$l$e of 1.5 seconds. Most infor - \\nmation is lost from STM as a result of interference, new \\ninformation that takes up the available slots. \\nAlthough the approximate model is clearly wrong in all its details, in \\nmost practical applications the details of STM do not matter: This \\napproximate model can be very valuable. Other approximate models \\nare easy to find. The time to find something can be approximated by \\nassuming that one object can be examined within the fovea at any one \\ntime, and that saccades take place at approximately 5 per second. Reac - \\ntion and decision times can be approximated by cycles of 100 milli- \\nseconds. The book by Card, Moran, and Newell (1983) provides \\nsophisticated examples of the power of approximate models of human \\ncognition. All these models can be criticized at the theoretical level. \\nBut they all provide numerical assessment of behavior that will be accu- \\nrate enough for almost all applications. \\nt: "}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.9}' message='Post details'
2023-11-25 10:49:59,524 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:49:59,526 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1314 request_id=10023409cce2219c20f21ccd2a9b02f1 response_code=200
2023-11-25 10:49:59,631 - DEBUG - Starting component PersistentLocalHnswSegment
2023-11-25 10:49:59,674 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2023-11-25 10:49:59,675 - DEBUG - api_version=None data='{"messages": [{"role": "system", "content": "Use the following pieces of context to answer the users question. \\nIf you don\'t know the answer, just say that you don\'t know, don\'t try to make up an answer.\\n----------------\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nA Frequently Asked Questions\\nA.1 Why does increasing model scale improve chain-of-thought prompting?\\nThe \\ufb01nding that successful chain-of-thought reasoning predictably emerges only at certain model\\nscales is intriguing. Scaling up language models has been shown to confer bene\\ufb01ts such as improved\\nperformance and sample ef\\ufb01ciency (Kaplan et al., 2020), but chain-of-thought reasoning is emergent\\nin the sense that its success cannot be predicted only by extrapolating the performance of small scale\\nmodels, as chain of thought actually hurts performance for most models smaller than 10B parameters.\\nThe question of why model scale improves chain-of-thought prompting is certainly multi-faceted, and\\nwe made a preliminary attempt to shed insight into it via error analysis. This small analysis involved\\nmanually reading 45 errors made by PaLM 62B and categorizing them into semantic understanding\\n(20 errors), one step missing (18 errors), and other errors (7 errors). The \\u201cother category\\u201d included\\nhallucinations, repetitive outputs, and symbol mapping errors. This categorization is a coarse one\\nborrowed from the initial error analysis done on LaMDA in Appendix D.2, for which categories were\\nconceived based on what improvements were needed to make the chain of thought correct.\\nAs shown in Figure 9, scaling PaLM to 540B parameters \\ufb01xed a substantial portion of errors in all\\nthree categories. Examples of semantic understanding and one-step missing errors that were \\ufb01xed by\\nscaling PaLM to 540B are given in Figure 10. This result appears consistent with a hypothesis that\\nlanguage models acquire a range of semantic understanding and logical reasoning skills as a function\\nof model scale (though note that model scale is often con\\ufb02ated with other factors, such as amount of\\ntraining compute).\\nSemantic understanding\\n(62B made 20 errors of this type, 540B \\ufb01xes 6 of them)One step missing\\n(62B made 18 errors of this type, 540B \\ufb01xes 12 of them)Other\\n(62B made 7 errors of this type, 540B \\ufb01xes 4 of them)Types of errors made by a 62B language model:Errors \\ufb01xed by scaling from 62B to 540B\\nFigure 9: Error analysis of 45 problems that PaLM 62B got incorrect. These errors were categorized\\nthat semantic understanding, one step missing, and other. The other category includes hallucinations,\\nrepetitive outputs, and symbol mapping errors. Scaling PaLM to 540B \\ufb01xed a substantial portion of\\nerrors in all categories.\\nThere are also three notable points regarding why small language models fail. The \\ufb01rst observation\\nis that small language models fail at even relatively easy symbol mapping tasks. As demonstrated\\nin Section 5, for even symbolic reasoning tasks that only require generalization to new examples\\nusing the same chain of thought logical structure that was given in the few-shot exemplars, small\\nlanguage models still failed. The second observation is that small language models seem to have\\ninherently weaker arithmetic abilities, as shown by Brown et al. (2020), the ability to do simple\\narithmetic operations (without semantic understanding) requires suf\\ufb01cient model scale. Finally, we\\nnoticed qualitatively that small language models often did not generate a \\ufb01nal answer that could be\\nparsed, due to either repetitions or logic that never arrived at a \\ufb01nal answer.\\nIn summary, the success of chain-of-thought reasoning as a result of model scale is a complicated\\nphenomena that likely involves a variety of emergent abilities (semantic understanding, symbol\\nmapping, staying on topic, arithmetic ability, faithfulness, etc). Future work could more thoroughly\\ninvestigate what properties of pretraining data, model architecture, and optimization objective causally\\nenable such reasoning capabilities.\\n16\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3\\n\\nlanguage models can generate chains of thought if demonstrations of chain-of-thought reasoning are\\nprovided in the exemplars for few-shot prompting.\\nFigure 1 shows an example of a model producing a chain of thought to solve a math word problem\\nthat it would have otherwise gotten incorrect. The chain of thought in this case resembles a solution\\nand can interpreted as one, but we still opt to call it a chain of thought to better capture the idea that it\\nmimics a step-by-step thought process for arriving at the answer (and also, solutions/explanations\\ntypically come after the \\ufb01nal answer (Narang et al., 2020; Wiegreffe et al., 2022; Lampinen et al.,\\n2022, inter alia )).\\nChain-of-thought prompting has several attractive properties as an approach for facilitating reasoning\\nin language models.\\n1.First, chain of thought, in principle, allows models to decompose multi-step problems into\\nintermediate steps, which means that additional computation can be allocated to problems\\nthat require more reasoning steps.\\n2.Second, a chain of thought provides an interpretable window into the behavior of the model,\\nsuggesting how it might have arrived at a particular answer and providing opportunities\\nto debug where the reasoning path went wrong (although fully characterizing a model\\u2019s\\ncomputations that support an answer remains an open question).\\n3.Third, chain-of-thought reasoning can be used for tasks such as math word problems,\\ncommonsense reasoning, and symbolic manipulation, and is potentially applicable (at least\\nin principle) to any task that humans can solve via language.\\n4.Finally, chain-of-thought reasoning can be readily elicited in suf\\ufb01ciently large off-the-shelf\\nlanguage models simply by including examples of chain of thought sequences into the\\nexemplars of few-shot prompting.\\nIn empirical experiments, we will observe the utility of chain-of-thought prompting for arithmetic\\nreasoning (Section 3), commonsense reasoning (Section 4), and symbolic reasoning (Section 5).\\n3 Arithmetic Reasoning\\nWe begin by considering math word problems of the form in Figure 1, which measure the arithmetic\\nreasoning ability of language models. Though simple for humans, arithmetic reasoning is a task where\\nlanguage models often struggle (Hendrycks et al., 2021; Patel et al., 2021, inter alia ). Strikingly, chain-\\nof-thought prompting when used with the 540B parameter language model performs comparably with\\ntask-speci\\ufb01c \\ufb01netuned models on several tasks, even achieving new state of the art on the challenging\\nGSM8K benchmark (Cobbe et al., 2021).\\n3.1 Experimental Setup\\nWe explore chain-of-thought prompting for various language models on multiple benchmarks.\\nBenchmarks. We consider the following \\ufb01ve math word problem benchmarks: (1)theGSM8K\\nbenchmark of math word problems (Cobbe et al., 2021), (2)theSV AMP dataset of math word\\nproblems with varying structures (Patel et al., 2021), (3)theASDiv dataset of diverse math word\\nproblems (Miao et al., 2020), (4)theAQuA dataset of algebraic word problems, and (5)theMA WPS\\nbenchmark (Koncel-Kedziorski et al., 2016). Example problems are given in Appendix Table 12.\\nStandard prompting. For the baseline, we consider standard few-shot prompting, popularized by\\nBrown et al. (2020), in which a language model is given in-context exemplars of input\\u2013output pairs\\nbefore outputting a prediction for a test-time example. Exemplars are formatted as questions and\\nanswers. The model gives the answer directly, as shown in Figure 1 (left).\\nChain-of-thought prompting. Our proposed approach is to augment each exemplar in few-shot\\nprompting with a chain of thought for an associated answer, as illustrated in Figure 1 (right). As most\\nof the datasets only have an evaluation split, we manually composed a set of eight few-shot exemplars\\nwith chains of thought for prompting\\u2014Figure 1 (right) shows one chain of thought exemplar, and the\\nfull set of exemplars is given in Appendix Table 20. (These particular exemplars did not undergo\\nprompt engineering; robustness is studied in Section 3.4 and Appendix A.2.) To investigate whether\\nchain-of-thought prompting in this form can successfully elicit successful reasoning across a range of\\n3"}, {"role": "user", "content": "Imagine what the author would think about neural networks?"}], "model": "gpt-3.5-turbo-1106", "max_tokens": null, "stream": false, "n": 1, "temperature": 0.5}' message='Post details'
2023-11-25 10:50:00,345 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2023-11-25 10:50:00,346 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=490 request_id=d7f9f27211aed363fcb19de73faa32de response_code=200
2023-11-25 10:50:00,361 - INFO - 0.8957580600764528
2023-11-25 10:50:00,367 - INFO - 0.8957580600764528
2023-11-25 10:50:00,367 - INFO - 0.8957580600764528
2023-11-25 10:50:00,367 - INFO - 0.8957580600764528
2023-11-25 10:50:00,368 - INFO - 0.8957580600764528
2023-11-25 10:50:00,396 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:50:00,398 - DEBUG - Loaded backend module://matplotlib_inline.backend_inline version unknown.
2023-11-25 10:50:00,444 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,446 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,447 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,448 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-11-25 10:50:00,449 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SukhumvitSet.ttc', name='Sukhumvit Set', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:50:00,450 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W4.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,450 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,450 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu Sangam MN.ttc', name='Telugu Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactRounded.ttf', name='.SF Compact Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmReg.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Herculanum.ttf', name='Herculanum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRejang-Regular.ttf', name='Noto Sans Rejang', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ明朝 ProN.ttc', name='Hiragino Mincho ProN', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNewTaiLue-Regular.ttf', name='Noto Sans New Tai Lue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Heavy.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/Library/Fonts/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,451 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72.ttc', name='Bodoni 72', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NewPeninimMT.ttc', name='New Peninim MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farah.ttc', name='Farah', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=200, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala Sangam MN.ttc', name='Sinhala Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Light.ttc', name='Heiti TC', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOsmanya-Regular.ttf', name='Noto Sans Osmanya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleMyungjo.ttf', name='AppleMyungjo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,452 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Light.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=300, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold.ttf', name='Verdana', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 3.9713636363636367
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DecoTypeNaskh.ttc', name='DecoType Naskh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Impact.ttf', name='Impact', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorGujarati.ttc', name='Kohinoor Gujarati', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer MN.ttc', name='Khmer MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Charter.ttc', name='Charter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Luminari.ttf', name='Luminari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,453 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Thuluth.ttf', name='Diwan Thuluth', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,454 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymBol.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,454 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni Ornaments.ttf', name='Bodoni Ornaments', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,454 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSRounded.ttf', name='.SF NS Rounded', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,454 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKayahLi-Regular.ttf', name='Noto Sans Kayah Li', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,454 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTMono.ttc', name='PT Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansHanunoo-Regular.ttf', name='Noto Sans Hanunoo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/LucidaGrande.ttc', name='Lucida Grande', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 2.872272727272727
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=700, stretch='condensed', size='scalable')) = 11.535
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagalog-Regular.ttf', name='Noto Sans Tagalog', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansAvestan-Regular.ttf', name='Noto Sans Avestan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYork.ttf', name='.New York', style='normal', variant='normal', weight=425, stretch='normal', size='scalable')) = 10.07375
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldSouthArabian-Regular.ttf', name='Noto Sans Old South Arabian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Futura.ttc', name='Futura', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymBol.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Palatino.ttc', name='Palatino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,455 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTifinagh-Regular.ttf', name='Noto Sans Tifinagh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansArmenian.ttc', name='Noto Sans Armenian', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSylotiNagri-Regular.ttf', name='Noto Sans Syloti Nagri', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Shree714.ttc', name='Shree Devanagari 714', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Bold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoNastaliq.ttc', name='Noto Nastaliq Urdu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Raanana.ttc', name='Raanana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Microsoft Sans Serif.ttf', name='Microsoft Sans Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSundanese-Regular.ttf', name='Noto Sans Sundanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactDisplay.ttf', name='.SF Compact Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,456 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sinhala MN.ttc', name='Sinhala MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AmericanTypewriter.ttc', name='American Typewriter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansYi-Regular.ttf', name='Noto Sans Yi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBolIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Italic.ttf', name='Verdana', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 4.6863636363636365
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Light.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeue.ttc', name='Helvetica Neue', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao MN.ttc', name='Lao MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Damascus.ttc', name='Damascus', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOlChiki-Regular.ttf', name='Noto Sans Ol Chiki', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,457 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Keyboard.ttf', name='.Keyboard', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniIta.otf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi MN.ttc', name='Gurmukhi MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MarkerFelt.ttc', name='Marker Felt', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpSmBol.otf', name='STIXIntegralsUpSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold Italic.ttf', name='Trebuchet MS', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Seravek.ttc', name='Seravek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneral.otf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 OS.ttc', name='Bodoni 72 Oldstyle', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Rockwell.ttc', name='Rockwell', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma Bold.ttf', name='Tahoma', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana Bold Italic.ttf', name='Verdana', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 4.971363636363637
2023-11-25 10:50:00,458 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalPahlavi-Regular.ttf', name='Noto Sans Inscriptional Pahlavi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Hiragino Sans GB.ttc', name='Hiragino Sans GB', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSyriac-Regular.ttf', name='Noto Sans Syriac', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansThaana-Regular.ttf', name='Noto Sans Thaana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Black.ttf', name='Arial Black', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMandaic-Regular.ttf', name='Noto Sans Mandaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W9.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCham-Regular.ttf', name='Noto Sans Cham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi.ttf', name='Mishafi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,459 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Ayuthaya.ttf', name='Ayuthaya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Semibold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Nadeem.ttc', name='Nadeem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Savoye LET.ttc', name='Savoye LET', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New.ttf', name='Courier New', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLimbu-Regular.ttf', name='Noto Sans Limbu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman.ttf', name='Times New Roman', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpBol.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold.ttf', name='Georgia', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SignPainter.ttc', name='SignPainter', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,460 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Beirut.ttc', name='Beirut', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuginese-Regular.ttf', name='Noto Sans Buginese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldItalic-Regular.ttf', name='Noto Sans Old Italic', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizOneSymReg.otf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSItalic.ttf', name='System Font', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansKannada.ttc', name='Noto Sans Kannada', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia.ttf', name='Georgia', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIDisplay.ttc', name='.Arabic UI Display', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 6 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kokonor.ttf', name='Kokonor', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold Italic.ttf', name='Times New Roman', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCypriot-Regular.ttf', name='Noto Sans Cypriot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,461 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial.ttf', name='Arial', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 6.413636363636363
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLisu-Regular.ttf', name='Noto Sans Lisu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansJavanese-Regular.otf', name='Noto Sans Javanese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Phosphate.ttc', name='Phosphate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Regular.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBol.otf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GillSans.ttc', name='Gill Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next Condensed.ttc', name='Avenir Next Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDBol.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Noteworthy.ttc', name='Noteworthy', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,462 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow.ttf', name='Arial Narrow', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Menlo.ttc', name='Menlo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam Sangam MN.ttc', name='Malayalam Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/HelveticaNeueDeskInterface.ttc', name='.Helvetica Neue DeskInterface', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Medium.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansChakma-Regular.ttf', name='Noto Sans Chakma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Athelas.ttc', name='Athelas', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ChalkboardSE.ttc', name='Chalkboard SE', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/STHeiti Medium.ttc', name='Heiti TC', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W2.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=250, stretch='normal', size='scalable')) = 10.1925
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Bold.ttf', name='Arial Narrow', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:50:00,463 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Regular.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text.ttc', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Muna.ttc', name='Muna', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSerifBalinese-Regular.ttf', name='Noto Serif Balinese', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Apple Chancery.ttf', name='Apple Chancery', style='normal', variant='normal', weight=0, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada MN.ttc', name='Kannada MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmBol.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Bold Italic.ttf', name='Georgia', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir.ttc', name='Avenir', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymBol.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansInscriptionalParthian-Regular.ttf', name='Noto Sans Inscriptional Parthian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,464 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBrahmi-Regular.ttf', name='Noto Sans Brahmi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS Bold.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar Sangam MN.ttc', name='Myanmar Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Semibold.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=600, stretch='condensed', size='scalable')) = 10.44
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gujarati Sangam MN.ttc', name='Gujarati Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Diwan Kufi.ttc', name='Diwan Kufi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Optima.ttc', name='Optima', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKaithi-Regular.ttf', name='Noto Sans Kaithi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDReg.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AppleGothic.ttf', name='AppleGothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Webdings.ttf', name='Webdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,465 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVarBol.otf', name='STIXVariants', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/KufiStandardGK.ttc', name='KufiStandardGK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 3.ttf', name='Wingdings 3', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTagbanwa-Regular.ttf', name='Noto Sans Tagbanwa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerifCaption.ttc', name='PT Serif Caption', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya Sangam MN.ttc', name='Oriya Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold Italic.ttf', name='Courier New', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Tarikh.ttc', name='Al Tarikh', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhoenician-Regular.ttf', name='Noto Sans Phoenician', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi.ttf', name='Gurmukhi MT', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,466 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Verdana.ttf', name='Verdana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 3.6863636363636365
2023-11-25 10:50:00,467 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ丸ゴ ProN W4.ttc', name='Hiragino Maru Gothic Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorTelugu.ttc', name='Kohinoor Telugu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiTham-Regular.ttf', name='Noto Sans Tai Tham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Galvji.ttc', name='Galvji', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Italic.ttf', name='Arial', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.413636363636363
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpDBol.otf', name='STIXIntegralsUpD', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralItalic.otf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,468 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Cochin.ttc', name='Cochin', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArabicUIText.ttc', name='.Arabic UI Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Outline 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla MN.ttc', name='Bangla MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Heavy.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Corsiva.ttc', name='Corsiva Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSamaritan-Regular.ttf', name='Noto Sans Samaritan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansImperialAramaic-Regular.ttf', name='Noto Sans Imperial Aramaic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,469 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Thin.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansPhagsPa-Regular.ttf', name='Noto Sans PhagsPa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymReg.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kefa.ttc', name='Kefa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Lao Sangam MN.ttf', name='Lao Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Myanmar MN.ttc', name='Myanmar MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,470 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGothic-Regular.ttf', name='Noto Sans Gothic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W0.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=100, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AppleSDGothicNeo.ttc', name='Apple SD Gothic Neo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/GujaratiMT.ttc', name='Gujarati MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFiveSymReg.otf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansVai-Regular.ttf', name='Noto Sans Vai', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Songti.ttc', name='Songti SC', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,471 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUni.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PlantagenetCherokee.ttf', name='Plantagenet Cherokee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Symbol.ttf', name='Symbol', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Malayalam MN.ttc', name='Malayalam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Times New Roman Bold.ttf', name='Times New Roman', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansGlagolitic-Regular.ttf', name='Noto Sans Glagolitic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Telugu MN.ttc', name='Telugu MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SnellRoundhand.ttc', name='Snell Roundhand', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansEgyptianHieroglyphs-Regular.ttf', name='Noto Sans Egyptian Hieroglyphs', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLydian-Regular.ttf', name='Noto Sans Lydian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,472 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Symbols.ttf', name='Apple Symbols', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXGeneralBolIta.otf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/PingFang.ttc', name='PingFang HK', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold Italic.ttf', name='Arial', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 7.698636363636363
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Andale Mono.ttf', name='Andale Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Al Nile.ttc', name='Al Nile', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W6.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=600, stretch='normal', size='scalable')) = 10.24
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizTwoSymBol.otf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizFourSymReg.otf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Waseem.ttc', name='Waseem', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,473 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil Sangam MN.ttc', name='Tamil Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tamil MN.ttc', name='Tamil MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/BigCaslon.ttf', name='Big Caslon', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ArialHB.ttc', name='Arial Hebrew', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansNKo-Regular.ttf', name='Noto Sans NKo', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Gurmukhi Sangam MN.ttc', name='Gurmukhi Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBamum-Regular.ttf', name='Noto Sans Bamum', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCuneiform-Regular.ttf', name='Noto Sans Cuneiform', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/EuphemiaCAS.ttc', name='Euphemia UCAS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Krungthep.ttf', name='Krungthep', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trebuchet MS Bold.ttf', name='Trebuchet MS', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,474 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Oriya MN.ttc', name='Oriya MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldTurkic-Regular.ttf', name='Noto Sans Old Turkic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkboard.ttc', name='Chalkboard', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Georgia Italic.ttf', name='Georgia', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bodoni 72 Smallcaps Book.ttf', name='Bodoni 72 Smallcaps', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMongolian-Regular.ttf', name='Noto Sans Mongolian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Bold.ttf', name='Courier New', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ZapfDingbats.ttf', name='Zapf Dingbats', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSans.ttc', name='PT Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Copperplate.ttc', name='Copperplate', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBuhid-Regular.ttf', name='Noto Sans Buhid', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,475 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansKharoshthi-Regular.ttf', name='Noto Sans Kharoshthi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bradley Hand Bold.ttf', name='Bradley Hand', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Courier New Italic.ttf', name='Courier New', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Devanagari Sangam MN.ttc', name='Devanagari Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baghdad.ttc', name='Baghdad', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Helvetica.ttc', name='Helvetica', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 7.322727272727273
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kannada Sangam MN.ttc', name='Kannada Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mishafi Gold.ttf', name='Mishafi Gold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOgham-Regular.ttf', name='Noto Sans Ogham', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Hoefler Text Ornaments.ttf', name='Hoefler Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Khmer Sangam MN.ttf', name='Khmer Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,476 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Farisi.ttf', name='Farisi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Avenir Next.ttc', name='Avenir Next', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Brush Script.ttf', name='Brush Script MT', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiViet-Regular.ttf', name='Noto Sans Tai Viet', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Narrow Italic.ttf', name='Arial Narrow', style='italic', variant='normal', weight=400, stretch='condensed', size='scalable')) = 11.25
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansTaiLe-Regular.ttf', name='Noto Sans Tai Le', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/PTSerif.ttc', name='PT Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSTextCondensed-Medium.otf', name='.SF NS Text Condensed', style='normal', variant='normal', weight=500, stretch='condensed', size='scalable')) = 10.344999999999999
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansRunic-Regular.ttf', name='Noto Sans Runic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Zapfino.ttf', name='Zapfino', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Bangla Sangam MN.ttc', name='Bangla Sangam MN', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,477 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/KohinoorBangla.ttc', name='Kohinoor Bangla', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansMeeteiMayek-Regular.ttf', name='Noto Sans Meetei Mayek', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansOriya.ttc', name='Noto Sans Oriya', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXVar.otf', name='STIXVariants', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Condensed Bold.ttf', name='DIN Condensed', style='normal', variant='normal', weight=700, stretch='condensed', size='scalable')) = 10.535
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntSmReg.otf', name='STIXIntegralsSm', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Silom.ttf', name='Silom', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Kohinoor.ttc', name='Kohinoor Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Times.ttc', name='Times', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLepcha-Regular.ttf', name='Noto Sans Lepcha', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Papyrus.ttc', name='Papyrus', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:50:00,478 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntUpReg.otf', name='STIXIntegralsUp', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Ultralight.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=400, stretch='condensed', size='scalable')) = 10.25
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLycian-Regular.ttf', name='Noto Sans Lycian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Skia.ttf', name='Skia', style='normal', variant='normal', weight=5, stretch='normal', size='scalable')) = 10.42525
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Baskerville.ttc', name='Baskerville', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Tahoma.ttf', name='Tahoma', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactText.ttf', name='.SF Compact Text', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DevanagariMT.ttc', name='Devanagari MT', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NewYorkItalic.ttf', name='.New York', style='italic', variant='normal', weight=425, stretch='normal', size='scalable')) = 11.07375
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMono.ttf', name='.SF NS Mono', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Bold.ttf', name='Arial', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 6.698636363636363
2023-11-25 10:50:00,479 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings 2.ttf', name='Wingdings 2', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/MuktaMahee.ttc', name='Mukta Mahee', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFCompactTextItalic.ttf', name='.SF Compact Text', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/ITFDevanagari.ttc', name='ITF Devanagari', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sana.ttc', name='Sana', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Comic Sans MS.ttf', name='Comic Sans MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Thonburi.ttc', name='Thonburi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Bold.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=800, stretch='condensed', size='scalable')) = 10.629999999999999
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Apple Braille Pinpoint 8 Dot.ttf', name='Apple Braille', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSDisplayCondensed-Black.otf', name='.SF NS Display Condensed', style='normal', variant='normal', weight=900, stretch='condensed', size='scalable')) = 10.725
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCoptic-Regular.ttf', name='Noto Sans Coptic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,480 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansSaurashtra-Regular.ttf', name='Noto Sans Saurashtra', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXSizThreeSymReg.otf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNSMonoItalic.ttf', name='.SF NS Mono', style='italic', variant='normal', weight=300, stretch='normal', size='scalable')) = 11.145
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXNonUniBol.otf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSerifMyanmar.ttc', name='Noto Serif Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W5.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=500, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/DIN Alternate Bold.ttf', name='DIN Alternate', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansBatak-Regular.ttf', name='Noto Sans Batak', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/InaiMathi-MN.ttc', name='InaiMathi', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W7.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Trattatello.ttf', name='Trattatello', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,481 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Chalkduster.ttf', name='Chalkduster', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Wingdings.ttf', name='Wingdings', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Didot.ttc', name='Didot', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Sathu.ttf', name='Sathu', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/GeezaPro.ttc', name='Geeza Pro', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansUgaritic-Regular.ttf', name='Noto Sans Ugaritic', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansCarian-Regular.ttf', name='Noto Sans Carian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/NotoSansMyanmar.ttc', name='Noto Sans Myanmar', style='normal', variant='normal', weight=900, stretch='normal', size='scalable')) = 10.525
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Marion.ttc', name='Marion', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansLinearB-Regular.ttf', name='Noto Sans Linear B', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,482 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Mshtakan.ttc', name='Mshtakan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Rounded Bold.ttf', name='Arial Rounded MT Bold', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/SuperClarendon.ttc', name='Superclarendon', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Arial Unicode.ttf', name='Arial Unicode MS', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/AquaKana.ttc', name='.Aqua Kana', style='normal', variant='normal', weight=300, stretch='normal', size='scalable')) = 10.145
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansOldPersian-Regular.ttf', name='Noto Sans Old Persian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/SFNS.ttf', name='System Font', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Kailasa.ttc', name='Kailasa', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/NotoSansShavian-Regular.ttf', name='Noto Sans Shavian', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/ヒラギノ角ゴシック W8.ttc', name='Hiragino Sans', style='normal', variant='normal', weight=800, stretch='normal', size='scalable')) = 10.43
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/AlBayan.ttc', name='Al Bayan', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/Iowan Old Style.ttc', name='Iowan Old Style', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,483 - DEBUG - findfont: score(FontEntry(fname='/System/Library/Fonts/Supplemental/STIXIntDReg.otf', name='STIXIntegralsD', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-11-25 10:50:00,484 - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/Users/kjams/.local/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
